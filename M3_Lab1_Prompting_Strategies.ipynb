{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lambdabypi/AppliedGenAIIE5374/blob/main/M3_Lab1_Prompting_Strategies.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Intro Section -->\n",
        "<div style=\"background: linear-gradient(135deg, #001a70 0%, #0055d4 100%); color: white; padding: 30px; border-radius: 12px; text-align: center; box-shadow: 0 4px 12px rgba(0,0,0,0.1);\">\n",
        "    <h1 style=\"margin-bottom: 10px; font-size: 32px;\">Introduction to Prompting Strategies</h1>\n",
        "    <p style=\"font-size: 18px; margin: 0;\">Instructor: <strong>Dr. Dehghani</strong></p>\n",
        "</div>\n",
        "\n",
        "<!-- Spacer -->\n",
        "<div style=\"height: 30px;\"></div>\n",
        "\n",
        "<!-- Why It Matters Section -->\n",
        "<div style=\"background: #ffffff; padding: 25px; border-radius: 10px; border-left: 6px solid #0055d4; box-shadow: 0 4px 8px rgba(0,0,0,0.05);\">\n",
        "    <h2 style=\"margin-top: 0; color: #001a70;\">Why Prompting Strategies Matter</h2>\n",
        "    <p style=\"font-size: 16px; line-height: 1.6;\">\n",
        "        Imagine you‚Äôre working with a junior engineer. You say:  \n",
        "        <em>‚ÄúOptimize the system.‚Äù</em><br>\n",
        "        They‚Äôll probably ask: <em>‚ÄúWhich system? Optimize for cost, speed, or energy? Any constraints?‚Äù</em> üßê\n",
        "    </p>\n",
        "    <p style=\"font-size: 16px; line-height: 1.6;\">\n",
        "        Now try this instead:  \n",
        "        <em>‚ÄúAnalyze the HVAC system and minimize energy consumption while keeping temperatures between 22-24¬∞C. Provide a cost breakdown.‚Äù</em>  \n",
        "    </p>\n",
        "    <p style=\"font-size: 16px; line-height: 1.6;\">\n",
        "        That‚Äôs not just a prompt‚Äîit‚Äôs a <strong>clear strategy</strong> with defined objectives and boundaries.\n",
        "        And that‚Äôs exactly what AI models need to perform at their best.\n",
        "    </p>\n",
        "</div>\n",
        "\n",
        "<!-- Tip Section -->\n",
        "<div style=\"background: #f5faff; padding: 20px; border-radius: 8px; border-left: 5px solid #0055d4; margin-top: 30px;\">\n",
        "    <h3 style=\"margin-top: 0; color: #0055d4;\">üí° Pro Tip</h3>\n",
        "    <p style=\"margin: 0; font-size: 16px; line-height: 1.6;\">\n",
        "        AI models appreciate well-structured instructions just like engineers appreciate complete design specs.\n",
        "        Be specific, set clear goals, and watch the results improve!\n",
        "    </p>\n",
        "</div>\n",
        "\n",
        "<!-- Upcoming Topics -->\n",
        "<div style=\"margin-top: 40px; text-align: center;\">\n",
        "    <h3 style=\"color: #001a70;\">What‚Äôs Ahead</h3>\n",
        "    <ul style=\"list-style: none; padding: 0; font-size: 16px; line-height: 1.8;\">\n",
        "        <li>üìö Basic Prompting Types</li>\n",
        "        <li>üß© Advanced Strategies</li>\n",
        "        <li>üìä Application-Specific Techniques</li>\n",
        "    </ul>\n",
        "    <p style=\"font-size: 16px; color: #333;\">Let‚Äôs engineer some powerful AI conversations! üõ†Ô∏è</p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "VuSW9V7pZvnn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Section Header -->\n",
        "<div style=\"background: linear-gradient(135deg, #001a70 0%, #0055d4 100%); color: white; padding: 25px; border-radius: 12px; text-align: center; box-shadow: 0 4px 12px rgba(0,0,0,0.1);\">\n",
        "    <h1 style=\"margin-bottom: 10px; font-size: 30px;\">üìö Basic Prompting Types</h1>\n",
        "</div>\n",
        "\n",
        "<!-- Spacer -->\n",
        "<div style=\"height: 25px;\"></div>\n",
        "\n",
        "<!-- Zero-Shot Prompting -->\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4; margin-bottom: 20px;\">\n",
        "    <h3 style=\"margin-top: 0; color: #001a70;\">1Ô∏è‚É£ Zero-Shot Prompting</h3>\n",
        "    <p style=\"font-size: 16px; line-height: 1.6;\">\n",
        "        Provide only the task without any examples.  \n",
        "        <strong>Use When:</strong> The task is simple and well-known by the model.  \n",
        "        <em>Example:</em> ‚ÄúTranslate 'Hello' to French.‚Äù\n",
        "    </p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "cjZ5fTTNbfyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# üìå Set Up LLM and OpenAI API\n",
        "# ==========================\n",
        "# Import required libraries\n",
        "from google.colab import userdata\n",
        "import openai\n",
        "import os\n",
        "\n",
        "# Load the OpenAI API key securely from Colab secrets\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Check that the API key was found\n",
        "if api_key is None:\n",
        "    raise ValueError(\"‚ùå API Key not found. Please store your OpenAI API key using Colab secrets.\")\n",
        "\n",
        "# Set API key as environment variable for OpenAI\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = openai.OpenAI(api_key=api_key)\n",
        "\n",
        "print(\"‚úÖ OpenAI API Key successfully loaded and environment is ready!\")\n",
        "\n",
        "# ==========================\n",
        "# üìå Set LLM Model to GPT-3.5\n",
        "# ==========================\n",
        "# Define which LLM model to use\n",
        "model_name = \"gpt-3.5-turbo\"\n",
        "\n",
        "print(f\"‚úÖ LLM model set to: {model_name}\")\n"
      ],
      "metadata": {
        "id": "dB3jBmICZwED",
        "outputId": "c8698301-e478-4956-8e5f-76406d856d38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ OpenAI API Key successfully loaded and environment is ready!\n",
            "‚úÖ LLM model set to: gpt-3.5-turbo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# üìå Zero-Shot Test: Hidden Formula Sequence\n",
        "# ==========================\n",
        "\n",
        "hard_sequence_prompt_zero = (\n",
        "    \"The sequence is: 3, 12, 27, 48, 75, ___. What‚Äôs next?\"\n",
        ")\n",
        "\n",
        "response_zero_hard = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": hard_sequence_prompt_zero}],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(\"üîπ LLM Response (Zero-Shot - Hard Sequence):\\n\")\n",
        "print(response_zero_hard.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "id": "AO4UhSJxb0Uv",
        "outputId": "1a9a23da-9089-44d8-fb35-c9e0a57a22b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ LLM Response (Zero-Shot - Hard Sequence):\n",
            "\n",
            "The pattern in the sequence is adding consecutive odd numbers to the previous number. \n",
            "\n",
            "3 + 9 = 12\n",
            "12 + 15 = 27\n",
            "27 + 21 = 48\n",
            "48 + 27 = 75\n",
            "\n",
            "Therefore, the next number in the sequence would be 75 + 33 = 108. \n",
            "\n",
            "So, the next number in the sequence is 108.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<!-- One-Shot Prompting -->\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4; margin-bottom: 20px;\">\n",
        "    <h3 style=\"margin-top: 0; color: #001a70;\">2Ô∏è‚É£ One-Shot Prompting</h3>\n",
        "    <p style=\"font-size: 16px; line-height: 1.6;\">\n",
        "        Provide one clear example along with the instruction.  \n",
        "        <strong>Use When:</strong> You want to guide the model‚Äôs behavior with a single example.  \n",
        "        <em>Example:</em> ‚ÄúTranslate 'Hello' to French: Bonjour. Now translate 'Goodbye'.‚Äù\n",
        "    </p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "zN2CjeJunlV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# üìå Zero-Shot vs One-Shot Comparison: Alternating Pattern Sequence (Correct One-Shot)\n",
        "# ==========================\n",
        "\n",
        "model_name = \"gpt-3.5-turbo\"\n",
        "\n",
        "# Zero-Shot Prompt (No Example)\n",
        "zero_shot_prompt = (\n",
        "    \"The sequence is: 1, 4, 2, 9, 3, 16, 4, ___. What number should replace the blank?\"\n",
        ")\n",
        "\n",
        "# One-Shot Prompt (One Example + New Question)\n",
        "one_shot_prompt = (\n",
        "    \"Example:\\n\"\n",
        "    \"The sequence is: 1, 1, 2, 4, 3, 9, ___. What‚Äôs next?\\n\"\n",
        "    \"Answer: 4.\\n\\n\"\n",
        "    \"Now solve this one:\\n\"\n",
        "    \"The sequence is: 1, 4, 2, 9, 3, 16, 4, ___. What number should replace the blank?\"\n",
        ")\n",
        "\n",
        "# Run Zero-Shot\n",
        "response_zero = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": zero_shot_prompt}],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Run One-Shot\n",
        "response_one = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": one_shot_prompt}],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Display Results\n",
        "print(\"üîπ Zero-Shot Response:\\n\" + \"-\"*40)\n",
        "print(response_zero.choices[0].message.content.strip())\n",
        "\n",
        "print(\"\\n\\nüîπ One-Shot Response:\\n\" + \"-\"*40)\n",
        "print(response_one.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "id": "AWI0m9_eciJK",
        "outputId": "4dcf363e-ae1d-45fc-977e-b5c374942265",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Zero-Shot Response:\n",
            "----------------------------------------\n",
            "The pattern is: \n",
            "\n",
            "1^2 = 1\n",
            "2^2 = 4\n",
            "3^2 = 9\n",
            "4^2 = 16\n",
            "\n",
            "Therefore, the next number in the sequence should be 5^2 = 25. \n",
            "\n",
            "So, the number that should replace the blank is 25.\n",
            "\n",
            "\n",
            "üîπ One-Shot Response:\n",
            "----------------------------------------\n",
            "Answer: 25.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<!-- Few-Shot Prompting -->\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4; margin-bottom: 20px;\">\n",
        "    <h3 style=\"margin-top: 0; color: #001a70;\">3Ô∏è‚É£ Few-Shot Prompting</h3>\n",
        "    <p style=\"font-size: 16px; line-height: 1.6;\">\n",
        "        Provide multiple examples to clearly demonstrate the pattern.  \n",
        "        <strong>Use When:</strong> The task is complex or requires understanding a specific format.  \n",
        "        <em>Example:</em>  \n",
        "        - ‚ÄúTranslate 'Hello' to French: Bonjour.‚Äù  \n",
        "        - ‚ÄúTranslate 'Goodbye' to French: Au revoir.‚Äù  \n",
        "        - ‚ÄúTranslate 'Thank you' to French: Merci.‚Äù  \n",
        "        Now translate 'Good night'.\n",
        "    </p>\n",
        "</div>\n",
        "\n",
        "<!-- Spacer -->\n",
        "<div style=\"height: 30px;\"></div>\n",
        "\n",
        "<!-- Closing Tip -->\n",
        "<div style=\"background: #f5faff; padding: 20px; border-radius: 8px; border-left: 5px solid #0055d4;\">\n",
        "    <h3 style=\"margin-top: 0; color: #0055d4;\">üí° Quick Reminder</h3>\n",
        "    <p style=\"margin: 0; font-size: 16px; line-height: 1.6;\">\n",
        "        The more complex the task, the more examples you should provide. But remember, too many examples can make prompts bulky and inefficient.\n",
        "    </p>\n",
        "</div>\n",
        "\n"
      ],
      "metadata": {
        "id": "DdXDGKuAnawA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# üìå Few-Shot Prompting Example: Ultra-Hard Pattern (3 Hidden Rules)\n",
        "# ==========================\n",
        "\n",
        "model_name = \"gpt-4-turbo\"  # Best for complex reasoning\n",
        "\n",
        "# Few-Shot Prompt with 2 Examples\n",
        "few_shot_prompt = (\n",
        "    \"Example 1:\\n\"\n",
        "    \"The sequence is: 1, 1, 2, 4, 3, 9, ___. What‚Äôs next?\\n\"\n",
        "    \"Answer: 4.\\n\\n\"\n",
        "    \"Example 2:\\n\"\n",
        "    \"The sequence is: 1, 1, 2, 4, 4, 9, 7, 16, ___. What‚Äôs next?\\n\"\n",
        "    \"Answer: 11.\\n\\n\"\n",
        "    \"Now try this one:\\n\"\n",
        "    \"The sequence is: 1, 1, 2, 4, 4, 9, 7, 16, 11, ___, 16, 36. What number should replace the blank?\"\n",
        ")\n",
        "\n",
        "# Run Few-Shot Prompt\n",
        "response_few = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": few_shot_prompt}],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Display Result\n",
        "print(\"üîπ Few-Shot Prompting (Two Examples Provided):\")\n",
        "print(\"-\" * 40)\n",
        "print(response_few.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "id": "3FLfQaF8mwB9",
        "outputId": "a59a7709-df57-4fad-b439-a82dafc3ae11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Few-Shot Prompting (Two Examples Provided):\n",
            "----------------------------------------\n",
            "To solve this sequence, let's analyze the pattern based on the given numbers and the answers from the previous examples:\n",
            "\n",
            "1, 1, 2, 4, 4, 9, 7, 16, 11, ___, 16, 36.\n",
            "\n",
            "From the previous examples:\n",
            "- Example 1: 1, 1, 2, 4, 3, 9, 4\n",
            "- Example 2: 1, 1, 2, 4, 4, 9, 7, 16, 11\n",
            "\n",
            "We can observe that the sequence seems to alternate between two patterns:\n",
            "1. Squares of integers.\n",
            "2. A sequence that increases by a certain rule.\n",
            "\n",
            "Let's break it down:\n",
            "- 1 (square of 1)\n",
            "- 1 (square of 1)\n",
            "- 2 (square of 1 + 1)\n",
            "- 4 (square of 2)\n",
            "- 4 (square of 2)\n",
            "- 9 (square of 3)\n",
            "- 7 (square of 2 + 3)\n",
            "- 16 (square of 4)\n",
            "- 11 (square of 3 + 2)\n",
            "- ___\n",
            "- 16 (square of 4)\n",
            "- 36 (square of 6)\n",
            "\n",
            "To find the missing number, we need to see if there's a pattern in the non-square numbers:\n",
            "- 2 (1 + 1)\n",
            "- 7 (4 + 3)\n",
            "- 11 (9 + 2)\n",
            "\n",
            "It seems that the non-square numbers are derived by adding the square root of the previous square number and another number that changes. Let's see if we can find a pattern in these additions:\n",
            "- 2 = 1 + 1\n",
            "- 7 = 4 + 3\n",
            "- 11 = 9 + 2\n",
            "\n",
            "The added numbers are decreasing (1, 3, 2). If we continue this pattern, the next addition should logically decrease further or reset:\n",
            "- 1, 3, 2 ‚Üí next could be 1 (or 0 if we consider a reset).\n",
            "\n",
            "If we use 1:\n",
            "- The last square before the blank is 16 (square of 4), so adding 1 gives us 16 + 1 = 17.\n",
            "\n",
            "Thus, the number that should replace the blank is 17.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "m0ICbL-NnaGw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† Advanced Prompting Techniques  \n",
        "\n",
        "Moving beyond basic prompting methods like zero-shot and few-shot, advanced strategies help enhance the reasoning and adaptability of large language models (LLMs). These techniques guide the model's thought process to handle complex tasks more effectively.\n",
        "\n",
        "---\n",
        "\n",
        "### üîó Chain-of-Thought (CoT) Prompting  \n",
        "\n",
        "Chain-of-Thought prompting encourages models to **explain their intermediate reasoning steps**, leading to more transparent and accurate conclusions. By structuring prompts to include logical steps, CoT improves the model‚Äôs ability to solve complex reasoning tasks.\n",
        "\n",
        "**Why is CoT Important?**  \n",
        "- ‚úîÔ∏è Improves performance on multi-step reasoning tasks.  \n",
        "- ‚úîÔ∏è Helps produce logically structured and coherent responses.  \n",
        "- ‚úîÔ∏è Breaks down complex problems into manageable steps.\n",
        "\n",
        "üìñ **Reference:** [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903)\n",
        "\n",
        "---\n",
        "\n",
        "*Next, explore practical examples of Chain-of-Thought prompting.*\n"
      ],
      "metadata": {
        "id": "cJYU0rOaTD5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# üìå Chain-of-Thought Demonstration: Make 110 with Five 5's\n",
        "# ==========================\n",
        "\n",
        "model_name = \"gpt-4-turbo\"\n",
        "\n",
        "# Zero-Shot Prompt (No Reasoning Encouraged)\n",
        "zero_shot_prompt = (\n",
        "    \"Use exactly five 5‚Äôs and only four operations (+, -, *, /) and parentheses to make 110.\"\n",
        ")\n",
        "\n",
        "# Chain-of-Thought Prompt (Encourages Step-by-Step Reasoning)\n",
        "cot_prompt = (\n",
        "    \"Let's solve this step by step.\\n\"\n",
        "    \"We need to use exactly five 5‚Äôs and only four operations (+, -, *, /) and parentheses to make 110.\\n\"\n",
        "    \"Step 1: Think about how we can combine the 5's to form larger numbers (e.g., 55).\\n\"\n",
        "    \"Step 2: Try to combine them logically to reach 110.\\n\"\n",
        "    \"Now, provide the final equation and the answer.\"\n",
        ")\n",
        "\n",
        "# Run Zero-Shot\n",
        "response_zero = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": zero_shot_prompt}],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Run Chain-of-Thought\n",
        "response_cot = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": cot_prompt}],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Display Results\n",
        "print(\"üîπ Zero-Shot Response (No Reasoning Encouraged):\\n\" + \"-\" * 50)\n",
        "print(response_zero.choices[0].message.content.strip())\n",
        "\n",
        "print(\"\\nüîπ Chain-of-Thought Response (Reasoning Encouraged):\\n\" + \"-\" * 50)\n",
        "print(response_cot.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "id": "rNdqf6qGnJY2",
        "outputId": "8a4ce409-8b3b-4cf1-a66f-a8092e829134",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Zero-Shot Response (No Reasoning Encouraged):\n",
            "--------------------------------------------------\n",
            "To achieve the number 110 using exactly five 5's and the operations (+, -, *, /) along with parentheses, you can arrange them as follows:\n",
            "\n",
            "\\[ 5 * (5 * 5 - 5) + 5 = 110 \\]\n",
            "\n",
            "Here's the breakdown:\n",
            "1. \\(5 * 5 = 25\\)\n",
            "2. \\(25 - 5 = 20\\)\n",
            "3. \\(5 * 20 = 100\\)\n",
            "4. \\(100 + 5 = 105\\)\n",
            "5. \\(105 + 5 = 110\\)\n",
            "\n",
            "Thus, \\(5 * (5 * 5 - 5) + 5 = 110\\).\n",
            "\n",
            "üîπ Chain-of-Thought Response (Reasoning Encouraged):\n",
            "--------------------------------------------------\n",
            "To solve this, let's follow the steps you outlined:\n",
            "\n",
            "Step 1: Consider how to combine the 5's to form larger numbers. One way to do this is to create the number 55 by combining two 5's.\n",
            "\n",
            "Step 2: Now, let's try to use the remaining three 5's along with the number 55 to reach 110.\n",
            "\n",
            "Here's one way to do it:\n",
            "- Use two 5's to make 55.\n",
            "- Use another two 5's to make another 55.\n",
            "- Now, add these two 55's together.\n",
            "\n",
            "The equation would be:\n",
            "55 + 55 = 110\n",
            "\n",
            "However, this uses only four 5's. To use exactly five 5's, we can adjust the equation slightly:\n",
            "- Use two 5's to make 55.\n",
            "- Use another two 5's to make another 55.\n",
            "- Use the last 5 as it is.\n",
            "\n",
            "Now, the equation becomes:\n",
            "55 + 55 - 5 + 5 = 110\n",
            "\n",
            "This equation uses exactly five 5's and reaches the target number 110.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úã Hands-On Experiment: Observations  \n",
        "\n",
        "üìå **Instructions:**  \n",
        "- Run your experiments by changing the model type (e.g., `gpt-3.5-turbo`, `gpt-4-turbo`, `gpt-o3`), temperature, and prompt style.  \n",
        "- You can **either attach a screenshot/image of your results** or **write a brief summary of your observations (max half a page)**.\n",
        "\n",
        "---\n",
        "\n",
        "- **Model Used:**  \n",
        "  _[Enter the model name you tried, e.g., gpt-3.5-turbo, gpt-4-turbo, or gpt-o3]_\n",
        "\n",
        "- **Temperature Setting:**  \n",
        "  _[Enter the temperature you used, e.g., 0.0, 0.5, 0.7]_\n",
        "\n",
        "- **Zero-Shot Result:**  \n",
        "  _[Did Zero-Shot solve the problem correctly? Yes/No. Add a short explanation or attach an image.]_\n",
        "\n",
        "- **Chain-of-Thought Result:**  \n",
        "  _[Did Chain-of-Thought solve the problem better? Yes/No. Add a short explanation or attach an image.]_\n",
        "\n",
        "- **Key Takeaways (Max Half Page or Screenshot):**  \n",
        "  _[Summarize what you observed. Did a specific model perform better? How did temperature affect the results? What worked best? Attach image or write here.]_\n",
        "\n",
        "---\n",
        "\n",
        "‚úçÔ∏è *Try at least two models and different temperatures. Compare the results and reflect on how prompting strategies influence performance!*\n"
      ],
      "metadata": {
        "id": "LQ6og568laaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# üìå Chain-of-Thought Demonstration: Make 110 with Five 5's using gpt-3.5-turbo\n",
        "# ==========================\n",
        "\n",
        "model_name = \"gpt-3.5-turbo\"\n",
        "\n",
        "# Zero-Shot Prompt (No Reasoning Encouraged)\n",
        "zero_shot_prompt = (\n",
        "    \"Use exactly five 5‚Äôs and only four operations (+, -, *, /) and parentheses to make 110.\"\n",
        ")\n",
        "\n",
        "# Chain-of-Thought Prompt (Encourages Step-by-Step Reasoning)\n",
        "cot_prompt = (\n",
        "    \"Let's solve this step by step.\\n\"\n",
        "    \"We need to use exactly five 5‚Äôs and only four operations (+, -, *, /) and parentheses to make 110.\\n\"\n",
        "    \"Step 1: Think about how we can combine the 5's to form larger numbers (e.g., 55).\\n\"\n",
        "    \"Step 2: Try to combine them logically to reach 110.\\n\"\n",
        "    \"Now, provide the final equation and the answer.\"\n",
        ")\n",
        "\n",
        "# Run Zero-Shot\n",
        "response_zero = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": zero_shot_prompt}],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Run Chain-of-Thought\n",
        "response_cot = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": cot_prompt}],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Display Results\n",
        "print(\"üîπ Zero-Shot Response (No Reasoning Encouraged):\\n\" + \"-\" * 50)\n",
        "print(response_zero.choices[0].message.content.strip())\n",
        "\n",
        "print(\"\\nüîπ Chain-of-Thought Response (Reasoning Encouraged):\\n\" + \"-\" * 50)\n",
        "print(response_cot.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "id": "HvcTsbGnveRU",
        "outputId": "b3a23e3e-8909-4a66-84d0-6622a38ccbe0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Zero-Shot Response (No Reasoning Encouraged):\n",
            "--------------------------------------------------\n",
            "(5 * 5) + (5 * 5) + 5 = 110\n",
            "\n",
            "üîπ Chain-of-Thought Response (Reasoning Encouraged):\n",
            "--------------------------------------------------\n",
            "Sure! Here's one way to reach 110 using five 5's:\n",
            "\n",
            "(5 * 5) + (5 * 5) + 5 = 110\n",
            "\n",
            "So, the final equation is (5 * 5) + (5 * 5) + 5 = 110, and the answer is 110.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chain-of-Thought Prompting Experiment Results\n",
        "\n",
        "**Model Used:** GPT-4-Turbo and GPT-3.5-Turbo  \n",
        "**Temperature Setting:** 0.0\n",
        "\n",
        "## Key Observations\n",
        "\n",
        "I ran experiments comparing zero-shot vs. chain-of-thought (CoT) prompting on two OpenAI models to solve the \"make 110 with five 5's\" problem. The results show interesting differences in reasoning capabilities and prompt responsiveness.\n",
        "\n",
        "GPT-3.5-Turbo produced identical solutions in both conditions: `(5 * 5) + (5 * 5) + 5 = 110`. Despite being prompted to show its work in the CoT condition, the model only added a brief introductory sentence before providing the same answer. This suggests limited benefit from explicit reasoning prompts with this model for this particular task.\n",
        "\n",
        "GPT-4-Turbo, however, demonstrated significant differences between conditions. In zero-shot, it provided `5 * (5 * 5 - 5) + 5 = 110` with a detailed breakdown of each step. In the CoT condition, it explored a completely different solution path, leading to `55 + 55 - 5 + 5 = 110` while explicitly tracking how it combined the digits.\n",
        "\n",
        "What's particularly interesting is that GPT-4 exhibited emergent reasoning abilities even without explicit prompting. It voluntarily provided step-by-step explanations in the zero-shot condition despite not being asked to show its work.\n",
        "\n",
        "The experiment highlights that model quality seems to be the primary factor in determining whether reasoning prompts are effective. For GPT-3.5, CoT prompting added minimal value, while for GPT-4, it encouraged exploration of alternative solution paths.\n",
        "\n",
        "These findings suggest that as models become more capable, they may benefit more from explicit reasoning prompts, though the strongest models might already employ reasoning internally regardless of prompting strategy."
      ],
      "metadata": {
        "id": "nQ5W2Fl6vrEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîÅ Self-Consistency Prompting\n",
        "\n",
        "While Chain-of-Thought (CoT) improves reasoning by encouraging step-by-step thinking, it may still produce **inconsistent or incorrect** answers, especially in complex scenarios.  \n",
        "**Self-Consistency Prompting** enhances CoT by asking the model to **generate multiple reasoning paths** and then select the most common or consistent final answer.\n",
        "\n",
        "### Why is Self-Consistency Useful?\n",
        "\n",
        "- ‚úÖ Reduces random reasoning errors.\n",
        "- ‚úÖ Boosts reliability on ambiguous or multi-path problems.\n",
        "- ‚úÖ Often improves performance on mathematical, logical, and symbolic tasks.\n",
        "\n",
        "üìñ **Reference**: [Self-Consistency Improves Chain of Thought Reasoning in Language Models](https://arxiv.org/abs/2203.11171)\n",
        "\n",
        "---\n",
        "\n",
        "*Next, we‚Äôll see how Self-Consistency works in action using a complex reasoning example.*\n"
      ],
      "metadata": {
        "id": "RN2Af6nAkKi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# üìå Comparing Chain-of-Thought vs. Self-Consistency Prompting\n",
        "# ==========================\n",
        "\n",
        "model_name = \"gpt-4-turbo\"  # Using GPT-4 for better reasoning\n",
        "\n",
        "# Define the problem prompt\n",
        "problem_prompt = (\n",
        "    \"If a train travels at 60 miles per hour and leaves at 2 PM, and another train leaves \"\n",
        "    \"the same station at 3 PM traveling at 90 miles per hour, when will the second train catch up to the first?\"\n",
        ")\n",
        "\n",
        "# Chain-of-Thought Prompt (Standard)\n",
        "cot_prompt = (\n",
        "    \"Let's solve this step by step.\\n\"\n",
        "    + problem_prompt\n",
        ")\n",
        "\n",
        "# Self-Consistency Prompt: Ask the model to produce multiple reasoning paths\n",
        "def run_self_consistency(prompt, num_attempts=5):\n",
        "    answers = []\n",
        "    for _ in range(num_attempts):\n",
        "        response = client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.7  # Add randomness to explore different reasoning paths\n",
        "        )\n",
        "        answer = response.choices[0].message.content.strip()\n",
        "        answers.append(answer)\n",
        "    return answers\n",
        "\n",
        "# Run Chain-of-Thought (Single Attempt)\n",
        "response_cot = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": cot_prompt}],\n",
        "    temperature=0\n",
        ")\n",
        "cot_answer = response_cot.choices[0].message.content.strip()\n",
        "\n",
        "# Run Self-Consistency (Multiple Attempts)\n",
        "sc_answers = run_self_consistency(cot_prompt, num_attempts=5)\n",
        "\n",
        "# Simple Majority Vote to Find Most Consistent Answer\n",
        "from collections import Counter\n",
        "most_common_answer = Counter(sc_answers).most_common(1)[0]\n",
        "\n",
        "# Display Results\n",
        "print(\"üîπ Chain-of-Thought Response (Single Attempt):\\n\" + \"-\" * 50)\n",
        "print(cot_answer)\n",
        "\n",
        "print(\"\\nüîπ Self-Consistency Responses (Multiple Attempts):\\n\" + \"-\" * 50)\n",
        "for idx, ans in enumerate(sc_answers, 1):\n",
        "    print(f\"Attempt {idx}: {ans}\")\n",
        "\n",
        "print(\"\\nüîπ Final Self-Consistency Selected Answer:\\n\" + \"-\" * 50)\n",
        "print(f\"Most Common Answer: {most_common_answer[0]}\\nAppeared {most_common_answer[1]} times.\")\n"
      ],
      "metadata": {
        "id": "yNWwXIahdaOX",
        "outputId": "84d93a9e-b313-45ab-a1f4-fd599f25453a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Chain-of-Thought Response (Single Attempt):\n",
            "--------------------------------------------------\n",
            "To find out when the second train will catch up to the first, we can start by calculating how far ahead the first train is when the second train starts.\n",
            "\n",
            "1. **Calculate the distance the first train travels in one hour:**\n",
            "   Since the first train leaves at 2 PM and travels at 60 miles per hour, by 3 PM (when the second train leaves), the first train will have traveled:\n",
            "   \\[\n",
            "   \\text{Distance} = \\text{Speed} \\times \\text{Time} = 60 \\text{ miles per hour} \\times 1 \\text{ hour} = 60 \\text{ miles}\n",
            "   \\]\n",
            "\n",
            "2. **Set up an equation to find when the second train catches up:**\n",
            "   Let \\( t \\) be the time in hours after 3 PM when the second train catches up to the first. At this time, both trains will have covered the same distance from the station.\n",
            "\n",
            "   - The first train's distance from the station at time \\( t \\) after 3 PM is:\n",
            "     \\[\n",
            "     \\text{Distance}_{\\text{first}} = 60 \\text{ miles} + 60 \\text{ miles per hour} \\times t\n",
            "     \\]\n",
            "   - The second train's distance from the station at time \\( t \\) after 3 PM is:\n",
            "     \\[\n",
            "     \\text{Distance}_{\\text{second}} = 90 \\text{ miles per hour} \\times t\n",
            "     \\]\n",
            "\n",
            "3. **Equating the distances and solving for \\( t \\):**\n",
            "   \\[\n",
            "   60 + 60t = 90t\n",
            "   \\]\n",
            "   Simplify and solve for \\( t \\):\n",
            "   \\[\n",
            "   60 = 90t - 60t\n",
            "   \\]\n",
            "   \\[\n",
            "   60 = 30t\n",
            "   \\]\n",
            "   \\[\n",
            "   t = \\frac{60}{30} = 2 \\text{ hours}\n",
            "   \\]\n",
            "\n",
            "4. **Determine the actual time of day when the second train catches up:**\n",
            "   Since \\( t = 2 \\) hours after 3 PM, the second train catches up at:\n",
            "   \\[\n",
            "   3 \\text{ PM} + 2 \\text{ hours} = 5 \\text{ PM}\n",
            "   \\]\n",
            "\n",
            "Therefore, the second train catches up to the first train at 5 PM.\n",
            "\n",
            "üîπ Self-Consistency Responses (Multiple Attempts):\n",
            "--------------------------------------------------\n",
            "Attempt 1: To find out when the second train will catch up to the first, we can use the concept of relative speed and the distances traveled by the trains.\n",
            "\n",
            "**Step 1: Calculate the distance covered by the first train when the second train starts.**\n",
            "Since the first train travels at 60 miles per hour, and it leaves at 2 PM, by the time the second train leaves at 3 PM, the first train would have traveled for 1 hour.\n",
            "\n",
            "\\[ \\text{Distance covered by first train in 1 hour} = 60 \\text{ miles per hour} \\times 1 \\text{ hour} = 60 \\text{ miles} \\]\n",
            "\n",
            "**Step 2: Determine the relative speed of the second train with respect to the first train.**\n",
            "The second train travels at 90 miles per hour, and the first train travels at 60 miles per hour. The relative speed of the second train with respect to the first is the difference in their speeds:\n",
            "\n",
            "\\[ \\text{Relative speed} = 90 \\text{ mph} - 60 \\text{ mph} = 30 \\text{ mph} \\]\n",
            "\n",
            "**Step 3: Calculate the time it will take for the second train to catch up.**\n",
            "The second train needs to cover the initial 60 miles gap between the two trains. Since the relative speed is 30 miles per hour, the time \\( t \\) required for the second train to catch up can be found using the formula for time:\n",
            "\n",
            "\\[ t = \\frac{\\text{Distance}}{\\text{Speed}} = \\frac{60 \\text{ miles}}{30 \\text{ mph}} = 2 \\text{ hours} \\]\n",
            "\n",
            "**Step 4: Determine the actual time of day when the second train catches up.**\n",
            "The second train leaves at 3 PM. If it takes 2 hours to catch up from 3 PM, it will catch up at:\n",
            "\n",
            "\\[ 3 \\text{ PM} + 2 \\text{ hours} = 5 \\text{ PM} \\]\n",
            "\n",
            "Thus, the second train will catch up to the first train at 5 PM.\n",
            "Attempt 2: To solve this problem, let's calculate the relative speeds and distances traveled by the two trains.\n",
            "\n",
            "1. **Speeds of the trains:**\n",
            "   - Train 1 speed = 60 mph\n",
            "   - Train 2 speed = 90 mph\n",
            "\n",
            "2. **Time difference in departure:**\n",
            "   - Train 1 leaves at 2 PM.\n",
            "   - Train 2 leaves at 3 PM, which is 1 hour later.\n",
            "\n",
            "3. **Distance traveled by Train 1 when Train 2 starts:**\n",
            "   Since Train 1 has a 1-hour head start and travels at 60 mph, the distance it covers in that hour is:\n",
            "   \\[\n",
            "   \\text{Distance} = \\text{Speed} \\times \\text{Time} = 60 \\text{ mph} \\times 1 \\text{ hour} = 60 \\text{ miles}\n",
            "   \\]\n",
            "\n",
            "4. **Relative speed of Train 2 compared to Train 1:**\n",
            "   Since Train 2 is catching up, we subtract the speed of Train 1 from the speed of Train 2:\n",
            "   \\[\n",
            "   \\text{Relative speed} = 90 \\text{ mph} - 60 \\text{ mph} = 30 \\text{ mph}\n",
            "   \\]\n",
            "\n",
            "5. **Time required for Train 2 to catch up:**\n",
            "   Train 2 needs to cover the initial 60 miles gap between them. At a relative speed of 30 mph, the time required to catch up is calculated as:\n",
            "   \\[\n",
            "   \\text{Time to catch up} = \\frac{\\text{Distance to catch up}}{\\text{Relative speed}} = \\frac{60 \\text{ miles}}{30 \\text{ mph}} = 2 \\text{ hours}\n",
            "   \\]\n",
            "\n",
            "6. **Time when Train 2 catches up:**\n",
            "   Since Train 2 leaves at 3 PM, adding the 2 hours it takes to catch up gives:\n",
            "   \\[\n",
            "   3 \\text{ PM} + 2 \\text{ hours} = 5 \\text{ PM}\n",
            "   \\]\n",
            "\n",
            "Therefore, Train 2 will catch up to Train 1 at 5 PM.\n",
            "Attempt 3: To solve this problem, we first need to determine how far the first train has traveled by the time the second train starts.\n",
            "\n",
            "1. **Calculate the distance traveled by the first train in one hour:**\n",
            "   - Speed of the first train = 60 miles per hour\n",
            "   - Time traveled before the second train starts = 1 hour (from 2 PM to 3 PM)\n",
            "   - Distance = Speed √ó Time = 60 miles/hour √ó 1 hour = 60 miles\n",
            "\n",
            "2. **Set up the equation to find when the second train catches up:**\n",
            "   - Let \\( t \\) be the time in hours after 3 PM when the second train catches up.\n",
            "   - Distance traveled by the first train by time \\( t \\) after 3 PM:\n",
            "     - It has already traveled 60 miles, and continues to travel at 60 mph.\n",
            "     - Total distance = 60 miles + 60 miles/hour √ó \\( t \\)\n",
            "   - Distance traveled by the second train by time \\( t \\) after 3 PM:\n",
            "     - It starts at 3 PM and travels at 90 mph.\n",
            "     - Total distance = 90 miles/hour √ó \\( t \\)\n",
            "\n",
            "3. **Equation for when distances are equal:**\n",
            "   - Set the distances equal to each other to find \\( t \\):\n",
            "     \\[\n",
            "     60 + 60t = 90t\n",
            "     \\]\n",
            "   - Simplify and solve for \\( t \\):\n",
            "     \\[\n",
            "     60 = 90t - 60t \\\\\n",
            "     60 = 30t \\\\\n",
            "     t = \\frac{60}{30} = 2 \\text{ hours}\n",
            "     \\]\n",
            "\n",
            "4. **Find the actual time when the second train catches up:**\n",
            "   - \\( t = 2 \\) hours after 3 PM\n",
            "   - 3 PM + 2 hours = 5 PM\n",
            "\n",
            "Thus, the second train catches up to the first train at 5 PM.\n",
            "Attempt 4: To solve this problem, we start by calculating how far the first train travels before the second train begins its journey. We then determine the rate at which the distance between the two trains closes, and use that to calculate when the second train catches up to the first.\n",
            "\n",
            "1. **Calculate the distance the first train travels in the first hour:**\n",
            "   - The first train travels at 60 miles per hour.\n",
            "   - In one hour (from 2 PM to 3 PM), the first train covers 60 miles.\n",
            "\n",
            "2. **Determine the relative speed of the two trains:**\n",
            "   - The second train travels at 90 miles per hour, and the first train travels at 60 miles per hour.\n",
            "   - The speed at which the distance between the two trains is closing is \\(90 - 60 = 30\\) miles per hour.\n",
            "\n",
            "3. **Calculate the time required for the second train to catch up:**\n",
            "   - The first train has a 60-mile head start.\n",
            "   - The second train closes the gap at a rate of 30 miles per hour.\n",
            "   - Time taken to catch up = Distance / Relative Speed = \\(60 \\text{ miles} / 30 \\text{ mph} = 2\\) hours.\n",
            "\n",
            "4. **Determine the catch-up time:**\n",
            "   - The second train leaves at 3 PM.\n",
            "   - It takes 2 hours to catch up.\n",
            "   - Therefore, the second train catches up to the first train at 3 PM + 2 hours = 5 PM.\n",
            "\n",
            "**Conclusion:**\n",
            "The second train catches up to the first train at 5 PM.\n",
            "Attempt 5: To find out when the second train will catch up to the first train, we start by calculating how far the first train travels by the time the second train departs.\n",
            "\n",
            "Given:\n",
            "- The speed of the first train = 60 miles per hour.\n",
            "- The first train departs at 2 PM.\n",
            "\n",
            "The second train departs:\n",
            "- At 3 PM.\n",
            "- The speed of the second train = 90 miles per hour.\n",
            "\n",
            "Time difference between the departures = 3 PM - 2 PM = 1 hour.\n",
            "\n",
            "In that 1 hour, the first train has traveled:\n",
            "Distance = Speed √ó Time = 60 miles per hour √ó 1 hour = 60 miles.\n",
            "\n",
            "Now, both trains are moving, and we need to calculate the time it takes for the second train to cover the 60-mile gap between it and the first train, and then catch up further.\n",
            "\n",
            "The speed difference between the two trains is:\n",
            "Speed difference = 90 miles per hour (second train) - 60 miles per hour (first train) = 30 miles per hour.\n",
            "\n",
            "This speed difference indicates how quickly the second train is catching up to the first train. The second train is catching up at a rate of 30 miles per hour.\n",
            "\n",
            "To find out how long it takes for the second train to catch up, we calculate the time to cover the 60-mile gap with the speed difference:\n",
            "Time = Distance / Speed difference = 60 miles / 30 miles per hour = 2 hours.\n",
            "\n",
            "Since the second train leaves at 3 PM, and it takes 2 hours to catch up to the first train, the time at which the second train catches up is:\n",
            "3 PM + 2 hours = 5 PM.\n",
            "\n",
            "Therefore, the second train catches up to the first train at 5 PM.\n",
            "\n",
            "üîπ Final Self-Consistency Selected Answer:\n",
            "--------------------------------------------------\n",
            "Most Common Answer: To find out when the second train will catch up to the first, we can use the concept of relative speed and the distances traveled by the trains.\n",
            "\n",
            "**Step 1: Calculate the distance covered by the first train when the second train starts.**\n",
            "Since the first train travels at 60 miles per hour, and it leaves at 2 PM, by the time the second train leaves at 3 PM, the first train would have traveled for 1 hour.\n",
            "\n",
            "\\[ \\text{Distance covered by first train in 1 hour} = 60 \\text{ miles per hour} \\times 1 \\text{ hour} = 60 \\text{ miles} \\]\n",
            "\n",
            "**Step 2: Determine the relative speed of the second train with respect to the first train.**\n",
            "The second train travels at 90 miles per hour, and the first train travels at 60 miles per hour. The relative speed of the second train with respect to the first is the difference in their speeds:\n",
            "\n",
            "\\[ \\text{Relative speed} = 90 \\text{ mph} - 60 \\text{ mph} = 30 \\text{ mph} \\]\n",
            "\n",
            "**Step 3: Calculate the time it will take for the second train to catch up.**\n",
            "The second train needs to cover the initial 60 miles gap between the two trains. Since the relative speed is 30 miles per hour, the time \\( t \\) required for the second train to catch up can be found using the formula for time:\n",
            "\n",
            "\\[ t = \\frac{\\text{Distance}}{\\text{Speed}} = \\frac{60 \\text{ miles}}{30 \\text{ mph}} = 2 \\text{ hours} \\]\n",
            "\n",
            "**Step 4: Determine the actual time of day when the second train catches up.**\n",
            "The second train leaves at 3 PM. If it takes 2 hours to catch up from 3 PM, it will catch up at:\n",
            "\n",
            "\\[ 3 \\text{ PM} + 2 \\text{ hours} = 5 \\text{ PM} \\]\n",
            "\n",
            "Thus, the second train will catch up to the first train at 5 PM.\n",
            "Appeared 1 times.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background: linear-gradient(135deg, #001a70 0%, #0055d4 100%); color: white; padding: 25px; border-radius: 12px; text-align: center;\">\n",
        "    <h1 style=\"margin-bottom: 10px;\">üìö Exploring More Advanced Prompting Strategies</h1>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4; margin-top: 20px;\">\n",
        "    <ul style=\"font-size: 16px; line-height: 1.8;\">\n",
        "        <li><strong>üß© Tree-of-Thought (ToT) Prompting:</strong> Explores multiple reasoning paths like a decision tree, helping the model evaluate and compare various solutions before choosing the best one.</li>\n",
        "        <li><strong>ü§ñ ReAct (Reasoning and Acting) Prompting:</strong> Combines reasoning steps with actions, including API calls or external tool usage. Ideal for interactive agents and dynamic decision-making tasks.</li>\n",
        "        <li><strong>üîÑ Reflexion Prompting:</strong> Encourages the model to critique its own responses and iteratively improve them, simulating self-correction and learning.</li>\n",
        "    </ul>\n",
        "</div>\n",
        "\n",
        "<div style=\"margin-top: 40px; text-align: center;\">\n",
        "    <h2 style=\"color: #001a70;\">‚úã Hands-On Task: Compare Prompting Strategies</h2>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #f5faff; padding: 20px; border-radius: 8px; border-left: 5px solid #0055d4;\">\n",
        "    <p style=\"font-size: 16px;\">\n",
        "        üìå <strong>Task Instructions:</strong><br>\n",
        "        - Experiment with <strong>Self-Consistency</strong>, <strong>Tree-of-Thought</strong>, and <strong>ReAct</strong> prompting methods.<br>\n",
        "        - Try to solve the following problem using each method and compare the results.\n",
        "    </p>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4; margin-top: 20px;\">\n",
        "    <h3>üß† <strong>Challenge Problem:</strong></h3>\n",
        "    <p style=\"font-size: 16px;\">A farmer has chickens and rabbits in a cage. There are 35 heads and 94 legs. How many chickens and rabbits are there?</p>\n",
        "</div>\n",
        "\n",
        "<div style=\"margin-top: 40px;\">\n",
        "    <ul style=\"font-size: 16px; line-height: 1.8;\">\n",
        "        <li>Try different models (e.g., <code>gpt-3.5-turbo</code>, <code>gpt-4-turbo</code>, <code>gpt-o3</code>).</li>\n",
        "        <li>Experiment with different temperatures (e.g., <code>0.0</code>, <code>0.5</code>, <code>0.7</code>).</li>\n",
        "        <li>Use both direct prompts and advanced strategies like CoT, Self-Consistency, or ReAct.</li>\n",
        "    </ul>\n",
        "</div>\n",
        "\n",
        "<div style=\"margin-top: 40px; text-align: center;\">\n",
        "    <h2 style=\"color: #001a70;\">üìñ Observations</h2>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4;\">\n",
        "    <ul style=\"font-size: 16px; line-height: 1.8;\">\n",
        "        <li><strong>Model and Strategy Used:</strong><br>_[Enter the model and prompting strategy you tried]_</li>\n",
        "        <li><strong>Was the Correct Answer Found?</strong><br>_[Yes/No. Explain briefly or attach a screenshot]_</li>\n",
        "        <li><strong>Key Takeaways (Max Half Page or Screenshot):</strong><br>_[Summarize how different strategies performed. What worked best? Why?]_</li>\n",
        "    </ul>\n",
        "</div>\n",
        "\n",
        "<div style=\"margin-top: 20px; text-align: center;\">\n",
        "    ‚úçÔ∏è <em>Hint: Try breaking down the problem into equations or ask the model to explain its steps before giving the final answer. Notice which strategies lead to faster and more accurate results!</em>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "Hfw5kDf5l_o_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# ‚úã Hands-On Code: Try Different Prompting Strategies and Models\n",
        "# ==========================\n",
        "\n",
        "# üìù Instructions:\n",
        "# - Change 'model_name' to try different models (e.g., \"gpt-3.5-turbo\", \"gpt-4-turbo\", \"gpt-o3\").\n",
        "# - Adjust 'temperature' to test how creativity affects reasoning.\n",
        "# - Try Self-Consistency by sampling multiple outputs and comparing answers.\n",
        "# - Optionally, explore Tree-of-Thought and ReAct patterns by modifying prompts.\n",
        "# ‚úÖ Your Experiment Starts Here üëá\n",
        "\n",
        "# ==========================\n",
        "# üìå Comparing Advanced Prompting Strategies for the Chickens and Rabbits Problem\n",
        "# ==========================\n",
        "\n",
        "# We'll test multiple models and strategies and compare results\n",
        "models_to_test = [\"gpt-3.5-turbo\", \"gpt-4-turbo\"]  # Add \"gpt-o3\" if you have access\n",
        "\n",
        "# Define the problem prompt\n",
        "problem = (\n",
        "    \"A farmer has chickens and rabbits in a cage. There are 35 heads and 94 legs. \"\n",
        "    \"How many chickens and rabbits are there?\"\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# Chain-of-Thought (CoT) Prompt\n",
        "# -------------------------\n",
        "cot_prompt = (\n",
        "    f\"Problem: {problem}\\n\\n\"\n",
        "    \"Let's solve this step by step:\\n\\n\"\n",
        "    \"1) Let's define variables: Let c be the number of chickens and r be the number of rabbits.\\n\"\n",
        "    \"2) Write equations based on the given information.\\n\"\n",
        "    \"3) Solve the system of equations.\\n\"\n",
        "    \"4) Verify the answer.\"\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# Tree-of-Thought (ToT) Prompt\n",
        "# -------------------------\n",
        "tot_prompt = (\n",
        "    f\"Problem: {problem}\\n\\n\"\n",
        "    \"Let's explore multiple solution paths and compare them to find the most reliable answer:\\n\\n\"\n",
        "    \"Path 1: Algebraic Solution\\n\"\n",
        "    \"- Define variables for chickens and rabbits\\n\"\n",
        "    \"- Set up equations for heads and legs\\n\"\n",
        "    \"- Solve the system of equations\\n\\n\"\n",
        "\n",
        "    \"Path 2: Trial and Error with Constraints\\n\"\n",
        "    \"- Total heads = 35, so possible combinations must sum to 35\\n\"\n",
        "    \"- For each combination, calculate total legs and check against 94\\n\"\n",
        "    \"- Find the combination that matches exactly\\n\\n\"\n",
        "\n",
        "    \"Path 3: Working Backward from Legs\\n\"\n",
        "    \"- If all animals were chickens (2 legs each), we would have 70 legs\\n\"\n",
        "    \"- The extra legs (94 - 70 = 24) must come from rabbits having 2 more legs than chickens\\n\"\n",
        "    \"- Calculate how many rabbits based on extra legs\\n\\n\"\n",
        "\n",
        "    \"Explore each path and determine which one leads to the correct answer. For each path, show your work, \"\n",
        "    \"note any potential errors, and state your confidence in the result.\\n\\n\"\n",
        "    \"Finally, compare the results from all paths and determine the final answer.\"\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# ReAct (Reasoning + Acting) Prompt\n",
        "# -------------------------\n",
        "react_prompt = (\n",
        "    f\"Problem: {problem}\\n\\n\"\n",
        "    \"Solve this problem using the ReAct format (Reasoning + Acting). Follow this structured approach:\\n\\n\"\n",
        "    \"Thought: [Describe your thinking about how to approach the problem]\\n\"\n",
        "    \"Action: [Define a specific step to take]\\n\"\n",
        "    \"Observation: [Note what you observe after taking that step]\\n\\n\"\n",
        "\n",
        "    \"Continue this Thought-Action-Observation cycle until you solve the problem. \"\n",
        "    \"Be explicit about each equation you write and each calculation you perform. \"\n",
        "    \"If you make a mistake, acknowledge it and correct yourself in the next cycle.\"\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# Self-Consistency Implementation\n",
        "# -------------------------\n",
        "def run_self_consistency(prompt, num_attempts=5, temperature=0.7):\n",
        "    answers = []\n",
        "    responses = []\n",
        "\n",
        "    for _ in range(num_attempts):\n",
        "        response = client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=temperature  # Add randomness to explore different reasoning paths\n",
        "        )\n",
        "\n",
        "        full_response = response.choices[0].message.content.strip()\n",
        "        responses.append(full_response)\n",
        "\n",
        "        # Extract final answer - look for patterns like \"answer is X chickens and Y rabbits\"\n",
        "        import re\n",
        "        answer_match = re.search(r\"(\\d+)\\s+chickens\\s+and\\s+(\\d+)\\s+rabbits\", full_response, re.IGNORECASE)\n",
        "        if answer_match:\n",
        "            chickens, rabbits = int(answer_match.group(1)), int(answer_match.group(2))\n",
        "            answers.append((chickens, rabbits))\n",
        "\n",
        "    # Find most common answer\n",
        "    from collections import Counter\n",
        "    if answers:\n",
        "        most_common_answer = Counter(answers).most_common(1)[0]\n",
        "        return {\n",
        "            \"responses\": responses,\n",
        "            \"answer_counts\": Counter(answers),\n",
        "            \"most_common\": most_common_answer\n",
        "        }\n",
        "    else:\n",
        "        return {\n",
        "            \"responses\": responses,\n",
        "            \"answer_counts\": {},\n",
        "            \"most_common\": None\n",
        "        }\n",
        "\n",
        "# -------------------------\n",
        "# Result Storage\n",
        "# -------------------------\n",
        "results = {\n",
        "    model: {\n",
        "        \"cot\": None,\n",
        "        \"tot\": None,\n",
        "        \"react\": None,\n",
        "        \"self_consistency\": None\n",
        "    }\n",
        "    for model in models_to_test\n",
        "}\n",
        "\n",
        "# -------------------------\n",
        "# Run Experiments\n",
        "# -------------------------\n",
        "for model_name in models_to_test:\n",
        "    print(f\"\\n\\n{'='*50}\")\n",
        "    print(f\"TESTING MODEL: {model_name}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    # Chain of Thought (Single attempt)\n",
        "    print(f\"Running Chain of Thought experiment with {model_name}...\")\n",
        "    response_cot = client.chat.completions.create(\n",
        "        model=model_name,\n",
        "        messages=[{\"role\": \"user\", \"content\": cot_prompt}],\n",
        "        temperature=0.0\n",
        "    )\n",
        "    results[model_name][\"cot\"] = response_cot.choices[0].message.content.strip()\n",
        "\n",
        "    # Tree of Thought (Single attempt)\n",
        "    print(f\"Running Tree of Thought experiment with {model_name}...\")\n",
        "    response_tot = client.chat.completions.create(\n",
        "        model=model_name,\n",
        "        messages=[{\"role\": \"user\", \"content\": tot_prompt}],\n",
        "        temperature=0.7\n",
        "    )\n",
        "    results[model_name][\"tot\"] = response_tot.choices[0].message.content.strip()\n",
        "\n",
        "    # ReAct (Single attempt)\n",
        "    print(f\"Running ReAct experiment with {model_name}...\")\n",
        "    response_react = client.chat.completions.create(\n",
        "        model=model_name,\n",
        "        messages=[{\"role\": \"user\", \"content\": react_prompt}],\n",
        "        temperature=0.5\n",
        "    )\n",
        "    results[model_name][\"react\"] = response_react.choices[0].message.content.strip()\n",
        "\n",
        "    # Self-Consistency (with CoT prompt)\n",
        "    print(f\"Running Self-Consistency experiment with {model_name}...\")\n",
        "    sc_results = run_self_consistency(cot_prompt, num_attempts=3, temperature=0.7)  # Reduced to 3 attempts to save tokens\n",
        "    results[model_name][\"self_consistency\"] = sc_results\n",
        "\n",
        "# -------------------------\n",
        "# Analysis Helper Functions\n",
        "# -------------------------\n",
        "def extract_answer(text):\n",
        "    \"\"\"Extracts the chicken and rabbit counts from the response text.\"\"\"\n",
        "    import re\n",
        "    answer_match = re.search(r\"(\\d+)\\s+chickens\\s+and\\s+(\\d+)\\s+rabbits\", text, re.IGNORECASE)\n",
        "    if answer_match:\n",
        "        return (int(answer_match.group(1)), int(answer_match.group(2)))\n",
        "    return None\n",
        "\n",
        "def is_correct(answer):\n",
        "    \"\"\"Checks if the extracted answer is correct (23 chickens and 12 rabbits).\"\"\"\n",
        "    return answer == (23, 12)\n",
        "\n",
        "def analyze_results(results):\n",
        "    \"\"\"Analyzes the results from all experiments and creates a summary.\"\"\"\n",
        "    summary = {}\n",
        "\n",
        "    for model in results:\n",
        "        summary[model] = {\n",
        "            \"cot\": {\"answer\": extract_answer(results[model][\"cot\"]), \"correct\": False},\n",
        "            \"tot\": {\"answer\": extract_answer(results[model][\"tot\"]), \"correct\": False},\n",
        "            \"react\": {\"answer\": extract_answer(results[model][\"react\"]), \"correct\": False},\n",
        "            \"self_consistency\": {\"answer\": None, \"correct\": False, \"consistency\": 0}\n",
        "        }\n",
        "\n",
        "        # Check correctness\n",
        "        if summary[model][\"cot\"][\"answer\"]:\n",
        "            summary[model][\"cot\"][\"correct\"] = is_correct(summary[model][\"cot\"][\"answer\"])\n",
        "\n",
        "        if summary[model][\"tot\"][\"answer\"]:\n",
        "            summary[model][\"tot\"][\"correct\"] = is_correct(summary[model][\"tot\"][\"answer\"])\n",
        "\n",
        "        if summary[model][\"react\"][\"answer\"]:\n",
        "            summary[model][\"react\"][\"correct\"] = is_correct(summary[model][\"react\"][\"answer\"])\n",
        "\n",
        "        # Handle self-consistency\n",
        "        sc_data = results[model][\"self_consistency\"]\n",
        "        if sc_data[\"most_common\"]:\n",
        "            answer, count = sc_data[\"most_common\"]\n",
        "            total = sum(sc_data[\"answer_counts\"].values())\n",
        "            summary[model][\"self_consistency\"][\"answer\"] = answer\n",
        "            summary[model][\"self_consistency\"][\"correct\"] = is_correct(answer)\n",
        "            summary[model][\"self_consistency\"][\"consistency\"] = count / total\n",
        "\n",
        "    return summary\n",
        "\n",
        "# -------------------------\n",
        "# Performance Analysis\n",
        "# -------------------------\n",
        "def analyze_performance(summary):\n",
        "    \"\"\"Generate performance metrics for each model and strategy.\"\"\"\n",
        "\n",
        "    metrics = {\n",
        "        \"model_performance\": {},\n",
        "        \"strategy_performance\": {\n",
        "            \"cot\": {\"correct\": 0, \"total\": 0},\n",
        "            \"tot\": {\"correct\": 0, \"total\": 0},\n",
        "            \"react\": {\"correct\": 0, \"total\": 0},\n",
        "            \"self_consistency\": {\"correct\": 0, \"total\": 0}\n",
        "        },\n",
        "        \"overall_best\": {\"model\": None, \"strategy\": None, \"score\": 0}\n",
        "    }\n",
        "\n",
        "    # Calculate model performance\n",
        "    for model in summary:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for strategy in summary[model]:\n",
        "            if summary[model][strategy][\"correct\"]:\n",
        "                correct += 1\n",
        "            total += 1\n",
        "\n",
        "            # Update strategy performance\n",
        "            if summary[model][strategy][\"correct\"]:\n",
        "                metrics[\"strategy_performance\"][strategy][\"correct\"] += 1\n",
        "            metrics[\"strategy_performance\"][strategy][\"total\"] += 1\n",
        "\n",
        "        metrics[\"model_performance\"][model] = {\n",
        "            \"correct\": correct,\n",
        "            \"total\": total,\n",
        "            \"accuracy\": correct / total if total > 0 else 0\n",
        "        }\n",
        "\n",
        "        # Check if this is the best model so far\n",
        "        if correct > metrics[\"overall_best\"][\"score\"]:\n",
        "            metrics[\"overall_best\"][\"model\"] = model\n",
        "            metrics[\"overall_best\"][\"score\"] = correct\n",
        "\n",
        "    # Calculate strategy performance percentages\n",
        "    for strategy in metrics[\"strategy_performance\"]:\n",
        "        strategy_data = metrics[\"strategy_performance\"][strategy]\n",
        "        strategy_data[\"accuracy\"] = strategy_data[\"correct\"] / strategy_data[\"total\"] if strategy_data[\"total\"] > 0 else 0\n",
        "\n",
        "        # Check if this is the best strategy so far\n",
        "        if strategy_data[\"accuracy\"] > metrics[\"overall_best\"].get(\"strategy_score\", 0):\n",
        "            metrics[\"overall_best\"][\"strategy\"] = strategy\n",
        "            metrics[\"overall_best\"][\"strategy_score\"] = strategy_data[\"accuracy\"]\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# Visualize results (optional - requires matplotlib)\n",
        "def visualize_results(summary, metrics):\n",
        "    \"\"\"Create visualizations of the results.\"\"\"\n",
        "    try:\n",
        "        import matplotlib.pyplot as plt\n",
        "        import numpy as np\n",
        "\n",
        "        # Set up the figure and axes\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "        # Model performance bar chart\n",
        "        models = list(metrics[\"model_performance\"].keys())\n",
        "        accuracies = [metrics[\"model_performance\"][model][\"accuracy\"] * 100 for model in models]\n",
        "\n",
        "        ax1.bar(models, accuracies)\n",
        "        ax1.set_ylim(0, 100)\n",
        "        ax1.set_ylabel(\"Accuracy (%)\")\n",
        "        ax1.set_title(\"Model Performance\")\n",
        "\n",
        "        # Strategy performance bar chart\n",
        "        strategies = list(metrics[\"strategy_performance\"].keys())\n",
        "        strategy_accuracies = [metrics[\"strategy_performance\"][strategy][\"accuracy\"] * 100 for strategy in strategies]\n",
        "\n",
        "        ax2.bar(strategies, strategy_accuracies)\n",
        "        ax2.set_ylim(0, 100)\n",
        "        ax2.set_ylabel(\"Accuracy (%)\")\n",
        "        ax2.set_title(\"Strategy Performance\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"prompting_strategy_results.png\")\n",
        "        print(\"\\nVisualization saved as 'prompting_strategy_results.png'\")\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"\\nMatplotlib not available. Skipping visualization.\")\n",
        "\n",
        "# -------------------------\n",
        "# Display Results\n",
        "# -------------------------\n",
        "print(\"\\n\\n\" + \"=\"*80)\n",
        "print(\"RESULTS SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "summary = analyze_results(results)\n",
        "performance = analyze_performance(summary)\n",
        "\n",
        "# Create a comparison table\n",
        "from tabulate import tabulate\n",
        "\n",
        "table_data = []\n",
        "headers = [\"Model\", \"Strategy\", \"Answer\", \"Correct?\", \"Notes\"]\n",
        "\n",
        "for model in summary:\n",
        "    for strategy in [\"cot\", \"tot\", \"react\", \"self_consistency\"]:\n",
        "        result = summary[model][strategy]\n",
        "\n",
        "        if strategy == \"self_consistency\":\n",
        "            answer_str = f\"{result['answer'][0]} chickens, {result['answer'][1]} rabbits\" if result['answer'] else \"No consistent answer\"\n",
        "            notes = f\"Consistency: {result['consistency']*100:.1f}%\" if result['answer'] else \"N/A\"\n",
        "        else:\n",
        "            answer_str = f\"{result['answer'][0]} chickens, {result['answer'][1]} rabbits\" if result['answer'] else \"Couldn't extract answer\"\n",
        "            notes = \"\"\n",
        "\n",
        "        table_data.append([\n",
        "            model,\n",
        "            strategy.upper(),\n",
        "            answer_str,\n",
        "            \"‚úì\" if result[\"correct\"] else \"‚úó\",\n",
        "            notes\n",
        "        ])\n",
        "\n",
        "print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
        "\n",
        "# Print performance summary\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PERFORMANCE SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Model performance\n",
        "print(\"\\nModel Performance:\")\n",
        "for model, perf in performance[\"model_performance\"].items():\n",
        "    print(f\"- {model}: {perf['correct']}/{perf['total']} correct ({perf['accuracy']*100:.1f}%)\")\n",
        "\n",
        "# Strategy performance\n",
        "print(\"\\nStrategy Performance:\")\n",
        "for strategy, perf in performance[\"strategy_performance\"].items():\n",
        "    print(f\"- {strategy.upper()}: {perf['correct']}/{perf['total']} correct ({perf['accuracy']*100:.1f}%)\")\n",
        "\n",
        "# Best overall\n",
        "print(f\"\\nBest Model: {performance['overall_best']['model']}\")\n",
        "print(f\"Best Strategy: {performance['overall_best']['strategy'].upper()}\")\n",
        "\n",
        "# Create visualization (optional)\n",
        "try:\n",
        "    visualize_results(summary, performance)\n",
        "except Exception as e:\n",
        "    print(f\"\\nVisualization error: {e}\")\n",
        "\n",
        "# -------------------------\n",
        "# Print Detailed Results (Optional)\n",
        "# -------------------------\n",
        "print_details = False  # Set to True if you want to see the full responses\n",
        "\n",
        "if print_details:\n",
        "    for model in results:\n",
        "        print(f\"\\n\\n{'='*50}\")\n",
        "        print(f\"DETAILED RESULTS FOR {model}\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "        print(\"\\nüîπ Chain-of-Thought Response:\\n\" + \"-\" * 50)\n",
        "        print(results[model][\"cot\"])\n",
        "\n",
        "        print(\"\\nüîπ Tree-of-Thought Response:\\n\" + \"-\" * 50)\n",
        "        print(results[model][\"tot\"])\n",
        "\n",
        "        print(\"\\nüîπ ReAct Response:\\n\" + \"-\" * 50)\n",
        "        print(results[model][\"react\"])\n",
        "\n",
        "        print(\"\\nüîπ Self-Consistency Results:\\n\" + \"-\" * 50)\n",
        "        sc_results = results[model][\"self_consistency\"]\n",
        "        if sc_results[\"most_common\"]:\n",
        "            answer, count = sc_results[\"most_common\"]\n",
        "            print(f\"Most Common Answer: {answer[0]} chickens and {answer[1]} rabbits\")\n",
        "            print(f\"This answer appeared {count} out of {len(sc_results['responses'])} times\")\n",
        "\n",
        "            print(\"\\nAnswer Distribution:\")\n",
        "            for answer, count in sc_results[\"answer_counts\"].items():\n",
        "                print(f\"- {answer[0]} chickens and {answer[1]} rabbits: {count} times\")\n",
        "        else:\n",
        "            print(\"No consistent answers found\")\n"
      ],
      "metadata": {
        "id": "5kYqO4FgkJd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background: linear-gradient(135deg, #001a70 0%, #0055d4 100%); color: white; padding: 25px; border-radius: 12px; text-align: center;\">\n",
        "    <h1 style=\"margin-bottom: 10px;\">üìå Conclusion</h1>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4; margin-top: 20px;\">\n",
        "    <p style=\"font-size: 16px; line-height: 1.8;\">\n",
        "        In this hands-on exploration, different advanced prompting strategies were tested to solve reasoning-based challenges.\n",
        "        Through experimenting with <strong>Chain-of-Thought (CoT)</strong>, <strong>Self-Consistency</strong>, and other methods,\n",
        "        the following key insights were observed:\n",
        "    </p>\n",
        "    <ul style=\"font-size: 16px; line-height: 1.8;\">\n",
        "        <li>Advanced prompting techniques significantly improve model performance, especially on complex, multi-step problems.</li>\n",
        "        <li>Changing the <strong>model type</strong> and <strong>temperature</strong> can drastically affect reasoning quality and creativity.</li>\n",
        "        <li>Some strategies, like <strong>Self-Consistency</strong>, help reduce random errors by exploring multiple reasoning paths.</li>\n",
        "        <li>For ambiguous or challenging problems, combining strategies (e.g., CoT + Self-Consistency) often leads to the most reliable results.</li>\n",
        "    </ul>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #f5faff; padding: 20px; border-radius: 8px; border-left: 5px solid #0055d4; margin-top: 20px;\">\n",
        "    <p style=\"font-size: 16px; font-style: italic;\">\n",
        "        üìñ <em>Remember: Prompt engineering is both an art and a science. The more you experiment, the better you understand how to guide LLMs effectively!</em>\n",
        "    </p>\n",
        "</div>\n",
        "\n",
        "<div style=\"margin-top: 40px; text-align: center;\">\n",
        "    <h3 style=\"color: #001a70;\">‚úçÔ∏è Final Reflection</h3>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4;\">\n",
        "    <p style=\"font-size: 16px;\">\n",
        "        _[Write 2-3 sentences summarizing what you personally learned about prompting strategies and how model selection or temperature influenced the results.]_\n",
        "    </p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "sivjpWXsmlUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2WJRwTsOmlrs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}