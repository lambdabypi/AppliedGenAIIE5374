{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lambdabypi/AppliedGenAIIE5374/blob/main/M3_Lab1_Prompting_Strategies.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Intro Section -->\n",
        "<div style=\"background: linear-gradient(135deg, #001a70 0%, #0055d4 100%); color: white; padding: 30px; border-radius: 12px; text-align: center; box-shadow: 0 4px 12px rgba(0,0,0,0.1);\">\n",
        "    <h1 style=\"margin-bottom: 10px; font-size: 32px;\">Introduction to Prompting Strategies</h1>\n",
        "    <p style=\"font-size: 18px; margin: 0;\">Instructor: <strong>Dr. Dehghani</strong></p>\n",
        "</div>\n",
        "\n",
        "<!-- Spacer -->\n",
        "<div style=\"height: 30px;\"></div>\n",
        "\n",
        "<!-- Why It Matters Section -->\n",
        "<div style=\"background: #ffffff; padding: 25px; border-radius: 10px; border-left: 6px solid #0055d4; box-shadow: 0 4px 8px rgba(0,0,0,0.05);\">\n",
        "    <h2 style=\"margin-top: 0; color: #001a70;\">Why Prompting Strategies Matter</h2>\n",
        "    <p style=\"font-size: 16px; line-height: 1.6;\">\n",
        "        Imagine you‚Äôre working with a junior engineer. You say:  \n",
        "        <em>‚ÄúOptimize the system.‚Äù</em><br>\n",
        "        They‚Äôll probably ask: <em>‚ÄúWhich system? Optimize for cost, speed, or energy? Any constraints?‚Äù</em> üßê\n",
        "    </p>\n",
        "    <p style=\"font-size: 16px; line-height: 1.6;\">\n",
        "        Now try this instead:  \n",
        "        <em>‚ÄúAnalyze the HVAC system and minimize energy consumption while keeping temperatures between 22-24¬∞C. Provide a cost breakdown.‚Äù</em>  \n",
        "    </p>\n",
        "    <p style=\"font-size: 16px; line-height: 1.6;\">\n",
        "        That‚Äôs not just a prompt‚Äîit‚Äôs a <strong>clear strategy</strong> with defined objectives and boundaries.\n",
        "        And that‚Äôs exactly what AI models need to perform at their best.\n",
        "    </p>\n",
        "</div>\n",
        "\n",
        "<!-- Tip Section -->\n",
        "<div style=\"background: #f5faff; padding: 20px; border-radius: 8px; border-left: 5px solid #0055d4; margin-top: 30px;\">\n",
        "    <h3 style=\"margin-top: 0; color: #0055d4;\">üí° Pro Tip</h3>\n",
        "    <p style=\"margin: 0; font-size: 16px; line-height: 1.6;\">\n",
        "        AI models appreciate well-structured instructions just like engineers appreciate complete design specs.\n",
        "        Be specific, set clear goals, and watch the results improve!\n",
        "    </p>\n",
        "</div>\n",
        "\n",
        "<!-- Upcoming Topics -->\n",
        "<div style=\"margin-top: 40px; text-align: center;\">\n",
        "    <h3 style=\"color: #001a70;\">What‚Äôs Ahead</h3>\n",
        "    <ul style=\"list-style: none; padding: 0; font-size: 16px; line-height: 1.8;\">\n",
        "        <li>üìö Basic Prompting Types</li>\n",
        "        <li>üß© Advanced Strategies</li>\n",
        "        <li>üìä Application-Specific Techniques</li>\n",
        "    </ul>\n",
        "    <p style=\"font-size: 16px; color: #333;\">Let‚Äôs engineer some powerful AI conversations! üõ†Ô∏è</p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "VuSW9V7pZvnn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Section Header -->\n",
        "<div style=\"background: linear-gradient(135deg, #001a70 0%, #0055d4 100%); color: white; padding: 25px; border-radius: 12px; text-align: center; box-shadow: 0 4px 12px rgba(0,0,0,0.1);\">\n",
        "    <h1 style=\"margin-bottom: 10px; font-size: 30px;\">üìö Basic Prompting Types</h1>\n",
        "</div>\n",
        "\n",
        "<!-- Spacer -->\n",
        "<div style=\"height: 25px;\"></div>\n",
        "\n",
        "<!-- Zero-Shot Prompting -->\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4; margin-bottom: 20px;\">\n",
        "    <h3 style=\"margin-top: 0; color: #001a70;\">1Ô∏è‚É£ Zero-Shot Prompting</h3>\n",
        "    <p style=\"font-size: 16px; line-height: 1.6;\">\n",
        "        Provide only the task without any examples.  \n",
        "        <strong>Use When:</strong> The task is simple and well-known by the model.  \n",
        "        <em>Example:</em> ‚ÄúTranslate 'Hello' to French.‚Äù\n",
        "    </p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "cjZ5fTTNbfyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# üìå Set Up LLM and OpenAI API\n",
        "# ==========================\n",
        "# Import required libraries\n",
        "from google.colab import userdata\n",
        "import openai\n",
        "import os\n",
        "\n",
        "# Load the OpenAI API key securely from Colab secrets\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Check that the API key was found\n",
        "if api_key is None:\n",
        "    raise ValueError(\"‚ùå API Key not found. Please store your OpenAI API key using Colab secrets.\")\n",
        "\n",
        "# Set API key as environment variable for OpenAI\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = openai.OpenAI(api_key=api_key)\n",
        "\n",
        "print(\"‚úÖ OpenAI API Key successfully loaded and environment is ready!\")\n",
        "\n",
        "# ==========================\n",
        "# üìå Set LLM Model to GPT-3.5\n",
        "# ==========================\n",
        "# Define which LLM model to use\n",
        "model_name = \"gpt-3.5-turbo\"\n",
        "\n",
        "print(f\"‚úÖ LLM model set to: {model_name}\")\n"
      ],
      "metadata": {
        "id": "dB3jBmICZwED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8698301-e478-4956-8e5f-76406d856d38"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ OpenAI API Key successfully loaded and environment is ready!\n",
            "‚úÖ LLM model set to: gpt-3.5-turbo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# üìå Zero-Shot Test: Hidden Formula Sequence\n",
        "# ==========================\n",
        "\n",
        "hard_sequence_prompt_zero = (\n",
        "    \"The sequence is: 3, 12, 27, 48, 75, ___. What‚Äôs next?\"\n",
        ")\n",
        "\n",
        "response_zero_hard = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": hard_sequence_prompt_zero}],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(\"üîπ LLM Response (Zero-Shot - Hard Sequence):\\n\")\n",
        "print(response_zero_hard.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "id": "AO4UhSJxb0Uv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a9a23da-9089-44d8-fb35-c9e0a57a22b5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ LLM Response (Zero-Shot - Hard Sequence):\n",
            "\n",
            "The pattern in the sequence is adding consecutive odd numbers to the previous number. \n",
            "\n",
            "3 + 9 = 12\n",
            "12 + 15 = 27\n",
            "27 + 21 = 48\n",
            "48 + 27 = 75\n",
            "\n",
            "Therefore, the next number in the sequence would be 75 + 33 = 108. \n",
            "\n",
            "So, the next number in the sequence is 108.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<!-- One-Shot Prompting -->\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4; margin-bottom: 20px;\">\n",
        "    <h3 style=\"margin-top: 0; color: #001a70;\">2Ô∏è‚É£ One-Shot Prompting</h3>\n",
        "    <p style=\"font-size: 16px; line-height: 1.6;\">\n",
        "        Provide one clear example along with the instruction.  \n",
        "        <strong>Use When:</strong> You want to guide the model‚Äôs behavior with a single example.  \n",
        "        <em>Example:</em> ‚ÄúTranslate 'Hello' to French: Bonjour. Now translate 'Goodbye'.‚Äù\n",
        "    </p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "zN2CjeJunlV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# üìå Zero-Shot vs One-Shot Comparison: Alternating Pattern Sequence (Correct One-Shot)\n",
        "# ==========================\n",
        "\n",
        "model_name = \"gpt-3.5-turbo\"\n",
        "\n",
        "# Zero-Shot Prompt (No Example)\n",
        "zero_shot_prompt = (\n",
        "    \"The sequence is: 1, 4, 2, 9, 3, 16, 4, ___. What number should replace the blank?\"\n",
        ")\n",
        "\n",
        "# One-Shot Prompt (One Example + New Question)\n",
        "one_shot_prompt = (\n",
        "    \"Example:\\n\"\n",
        "    \"The sequence is: 1, 1, 2, 4, 3, 9, ___. What‚Äôs next?\\n\"\n",
        "    \"Answer: 4.\\n\\n\"\n",
        "    \"Now solve this one:\\n\"\n",
        "    \"The sequence is: 1, 4, 2, 9, 3, 16, 4, ___. What number should replace the blank?\"\n",
        ")\n",
        "\n",
        "# Run Zero-Shot\n",
        "response_zero = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": zero_shot_prompt}],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Run One-Shot\n",
        "response_one = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": one_shot_prompt}],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Display Results\n",
        "print(\"üîπ Zero-Shot Response:\\n\" + \"-\"*40)\n",
        "print(response_zero.choices[0].message.content.strip())\n",
        "\n",
        "print(\"\\n\\nüîπ One-Shot Response:\\n\" + \"-\"*40)\n",
        "print(response_one.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "id": "AWI0m9_eciJK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dcf363e-ae1d-45fc-977e-b5c374942265"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Zero-Shot Response:\n",
            "----------------------------------------\n",
            "The pattern is: \n",
            "\n",
            "1^2 = 1\n",
            "2^2 = 4\n",
            "3^2 = 9\n",
            "4^2 = 16\n",
            "\n",
            "Therefore, the next number in the sequence should be 5^2 = 25. \n",
            "\n",
            "So, the number that should replace the blank is 25.\n",
            "\n",
            "\n",
            "üîπ One-Shot Response:\n",
            "----------------------------------------\n",
            "Answer: 25.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<!-- Few-Shot Prompting -->\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4; margin-bottom: 20px;\">\n",
        "    <h3 style=\"margin-top: 0; color: #001a70;\">3Ô∏è‚É£ Few-Shot Prompting</h3>\n",
        "    <p style=\"font-size: 16px; line-height: 1.6;\">\n",
        "        Provide multiple examples to clearly demonstrate the pattern.  \n",
        "        <strong>Use When:</strong> The task is complex or requires understanding a specific format.  \n",
        "        <em>Example:</em>  \n",
        "        - ‚ÄúTranslate 'Hello' to French: Bonjour.‚Äù  \n",
        "        - ‚ÄúTranslate 'Goodbye' to French: Au revoir.‚Äù  \n",
        "        - ‚ÄúTranslate 'Thank you' to French: Merci.‚Äù  \n",
        "        Now translate 'Good night'.\n",
        "    </p>\n",
        "</div>\n",
        "\n",
        "<!-- Spacer -->\n",
        "<div style=\"height: 30px;\"></div>\n",
        "\n",
        "<!-- Closing Tip -->\n",
        "<div style=\"background: #f5faff; padding: 20px; border-radius: 8px; border-left: 5px solid #0055d4;\">\n",
        "    <h3 style=\"margin-top: 0; color: #0055d4;\">üí° Quick Reminder</h3>\n",
        "    <p style=\"margin: 0; font-size: 16px; line-height: 1.6;\">\n",
        "        The more complex the task, the more examples you should provide. But remember, too many examples can make prompts bulky and inefficient.\n",
        "    </p>\n",
        "</div>\n",
        "\n"
      ],
      "metadata": {
        "id": "DdXDGKuAnawA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# üìå Few-Shot Prompting Example: Ultra-Hard Pattern (3 Hidden Rules)\n",
        "# ==========================\n",
        "\n",
        "model_name = \"gpt-4-turbo\"  # Best for complex reasoning\n",
        "\n",
        "# Few-Shot Prompt with 2 Examples\n",
        "few_shot_prompt = (\n",
        "    \"Example 1:\\n\"\n",
        "    \"The sequence is: 1, 1, 2, 4, 3, 9, ___. What‚Äôs next?\\n\"\n",
        "    \"Answer: 4.\\n\\n\"\n",
        "    \"Example 2:\\n\"\n",
        "    \"The sequence is: 1, 1, 2, 4, 4, 9, 7, 16, ___. What‚Äôs next?\\n\"\n",
        "    \"Answer: 11.\\n\\n\"\n",
        "    \"Now try this one:\\n\"\n",
        "    \"The sequence is: 1, 1, 2, 4, 4, 9, 7, 16, 11, ___, 16, 36. What number should replace the blank?\"\n",
        ")\n",
        "\n",
        "# Run Few-Shot Prompt\n",
        "response_few = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": few_shot_prompt}],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Display Result\n",
        "print(\"üîπ Few-Shot Prompting (Two Examples Provided):\")\n",
        "print(\"-\" * 40)\n",
        "print(response_few.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "id": "3FLfQaF8mwB9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a59a7709-df57-4fad-b439-a82dafc3ae11"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Few-Shot Prompting (Two Examples Provided):\n",
            "----------------------------------------\n",
            "To solve this sequence, let's analyze the pattern based on the given numbers and the answers from the previous examples:\n",
            "\n",
            "1, 1, 2, 4, 4, 9, 7, 16, 11, ___, 16, 36.\n",
            "\n",
            "From the previous examples:\n",
            "- Example 1: 1, 1, 2, 4, 3, 9, 4\n",
            "- Example 2: 1, 1, 2, 4, 4, 9, 7, 16, 11\n",
            "\n",
            "We can observe that the sequence seems to alternate between two patterns:\n",
            "1. Squares of integers.\n",
            "2. A sequence that increases by a certain rule.\n",
            "\n",
            "Let's break it down:\n",
            "- 1 (square of 1)\n",
            "- 1 (square of 1)\n",
            "- 2 (square of 1 + 1)\n",
            "- 4 (square of 2)\n",
            "- 4 (square of 2)\n",
            "- 9 (square of 3)\n",
            "- 7 (square of 2 + 3)\n",
            "- 16 (square of 4)\n",
            "- 11 (square of 3 + 2)\n",
            "- ___\n",
            "- 16 (square of 4)\n",
            "- 36 (square of 6)\n",
            "\n",
            "To find the missing number, we need to see if there's a pattern in the non-square numbers:\n",
            "- 2 (1 + 1)\n",
            "- 7 (4 + 3)\n",
            "- 11 (9 + 2)\n",
            "\n",
            "It seems that the non-square numbers are derived by adding the square root of the previous square number and another number that changes. Let's see if we can find a pattern in these additions:\n",
            "- 2 = 1 + 1\n",
            "- 7 = 4 + 3\n",
            "- 11 = 9 + 2\n",
            "\n",
            "The added numbers are decreasing (1, 3, 2). If we continue this pattern, the next addition should logically decrease further or reset:\n",
            "- 1, 3, 2 ‚Üí next could be 1 (or 0 if we consider a reset).\n",
            "\n",
            "If we use 1:\n",
            "- The last square before the blank is 16 (square of 4), so adding 1 gives us 16 + 1 = 17.\n",
            "\n",
            "Thus, the number that should replace the blank is 17.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "m0ICbL-NnaGw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† Advanced Prompting Techniques  \n",
        "\n",
        "Moving beyond basic prompting methods like zero-shot and few-shot, advanced strategies help enhance the reasoning and adaptability of large language models (LLMs). These techniques guide the model's thought process to handle complex tasks more effectively.\n",
        "\n",
        "---\n",
        "\n",
        "### üîó Chain-of-Thought (CoT) Prompting  \n",
        "\n",
        "Chain-of-Thought prompting encourages models to **explain their intermediate reasoning steps**, leading to more transparent and accurate conclusions. By structuring prompts to include logical steps, CoT improves the model‚Äôs ability to solve complex reasoning tasks.\n",
        "\n",
        "**Why is CoT Important?**  \n",
        "- ‚úîÔ∏è Improves performance on multi-step reasoning tasks.  \n",
        "- ‚úîÔ∏è Helps produce logically structured and coherent responses.  \n",
        "- ‚úîÔ∏è Breaks down complex problems into manageable steps.\n",
        "\n",
        "üìñ **Reference:** [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903)\n",
        "\n",
        "---\n",
        "\n",
        "*Next, explore practical examples of Chain-of-Thought prompting.*\n"
      ],
      "metadata": {
        "id": "cJYU0rOaTD5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# üìå Chain-of-Thought Demonstration: Make 110 with Five 5's\n",
        "# ==========================\n",
        "\n",
        "model_name = \"gpt-4-turbo\"\n",
        "\n",
        "# Zero-Shot Prompt (No Reasoning Encouraged)\n",
        "zero_shot_prompt = (\n",
        "    \"Use exactly five 5‚Äôs and only four operations (+, -, *, /) and parentheses to make 110.\"\n",
        ")\n",
        "\n",
        "# Chain-of-Thought Prompt (Encourages Step-by-Step Reasoning)\n",
        "cot_prompt = (\n",
        "    \"Let's solve this step by step.\\n\"\n",
        "    \"We need to use exactly five 5‚Äôs and only four operations (+, -, *, /) and parentheses to make 110.\\n\"\n",
        "    \"Step 1: Think about how we can combine the 5's to form larger numbers (e.g., 55).\\n\"\n",
        "    \"Step 2: Try to combine them logically to reach 110.\\n\"\n",
        "    \"Now, provide the final equation and the answer.\"\n",
        ")\n",
        "\n",
        "# Run Zero-Shot\n",
        "response_zero = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": zero_shot_prompt}],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Run Chain-of-Thought\n",
        "response_cot = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": cot_prompt}],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Display Results\n",
        "print(\"üîπ Zero-Shot Response (No Reasoning Encouraged):\\n\" + \"-\" * 50)\n",
        "print(response_zero.choices[0].message.content.strip())\n",
        "\n",
        "print(\"\\nüîπ Chain-of-Thought Response (Reasoning Encouraged):\\n\" + \"-\" * 50)\n",
        "print(response_cot.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "id": "rNdqf6qGnJY2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a4ce409-8b3b-4cf1-a66f-a8092e829134"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Zero-Shot Response (No Reasoning Encouraged):\n",
            "--------------------------------------------------\n",
            "To achieve the number 110 using exactly five 5's and the operations (+, -, *, /) along with parentheses, you can arrange them as follows:\n",
            "\n",
            "\\[ 5 * (5 * 5 - 5) + 5 = 110 \\]\n",
            "\n",
            "Here's the breakdown:\n",
            "1. \\(5 * 5 = 25\\)\n",
            "2. \\(25 - 5 = 20\\)\n",
            "3. \\(5 * 20 = 100\\)\n",
            "4. \\(100 + 5 = 105\\)\n",
            "5. \\(105 + 5 = 110\\)\n",
            "\n",
            "Thus, \\(5 * (5 * 5 - 5) + 5 = 110\\).\n",
            "\n",
            "üîπ Chain-of-Thought Response (Reasoning Encouraged):\n",
            "--------------------------------------------------\n",
            "To solve this, let's follow the steps you outlined:\n",
            "\n",
            "Step 1: Consider how to combine the 5's to form larger numbers. One way to do this is to create the number 55 by combining two 5's.\n",
            "\n",
            "Step 2: Now, let's try to use the remaining three 5's along with the number 55 to reach 110.\n",
            "\n",
            "Here's one way to do it:\n",
            "- Use two 5's to make 55.\n",
            "- Use another two 5's to make another 55.\n",
            "- Now, add these two 55's together.\n",
            "\n",
            "The equation would be:\n",
            "55 + 55 = 110\n",
            "\n",
            "However, this uses only four 5's. To use exactly five 5's, we can adjust the equation slightly:\n",
            "- Use two 5's to make 55.\n",
            "- Use another two 5's to make another 55.\n",
            "- Use the last 5 as it is.\n",
            "\n",
            "Now, the equation becomes:\n",
            "55 + 55 - 5 + 5 = 110\n",
            "\n",
            "This equation uses exactly five 5's and reaches the target number 110.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úã Hands-On Experiment: Observations  \n",
        "\n",
        "üìå **Instructions:**  \n",
        "- Run your experiments by changing the model type (e.g., `gpt-3.5-turbo`, `gpt-4-turbo`, `gpt-o3`), temperature, and prompt style.  \n",
        "- You can **either attach a screenshot/image of your results** or **write a brief summary of your observations (max half a page)**.\n",
        "\n",
        "---\n",
        "\n",
        "- **Model Used:**  \n",
        "  _[Enter the model name you tried, e.g., gpt-3.5-turbo, gpt-4-turbo, or gpt-o3]_\n",
        "\n",
        "- **Temperature Setting:**  \n",
        "  _[Enter the temperature you used, e.g., 0.0, 0.5, 0.7]_\n",
        "\n",
        "- **Zero-Shot Result:**  \n",
        "  _[Did Zero-Shot solve the problem correctly? Yes/No. Add a short explanation or attach an image.]_\n",
        "\n",
        "- **Chain-of-Thought Result:**  \n",
        "  _[Did Chain-of-Thought solve the problem better? Yes/No. Add a short explanation or attach an image.]_\n",
        "\n",
        "- **Key Takeaways (Max Half Page or Screenshot):**  \n",
        "  _[Summarize what you observed. Did a specific model perform better? How did temperature affect the results? What worked best? Attach image or write here.]_\n",
        "\n",
        "---\n",
        "\n",
        "‚úçÔ∏è *Try at least two models and different temperatures. Compare the results and reflect on how prompting strategies influence performance!*\n"
      ],
      "metadata": {
        "id": "LQ6og568laaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# üìå Chain-of-Thought Demonstration: Make 110 with Five 5's using gpt-3.5-turbo\n",
        "# ==========================\n",
        "\n",
        "model_name = \"gpt-3.5-turbo\"\n",
        "\n",
        "# Zero-Shot Prompt (No Reasoning Encouraged)\n",
        "zero_shot_prompt = (\n",
        "    \"Use exactly five 5‚Äôs and only four operations (+, -, *, /) and parentheses to make 110.\"\n",
        ")\n",
        "\n",
        "# Chain-of-Thought Prompt (Encourages Step-by-Step Reasoning)\n",
        "cot_prompt = (\n",
        "    \"Let's solve this step by step.\\n\"\n",
        "    \"We need to use exactly five 5‚Äôs and only four operations (+, -, *, /) and parentheses to make 110.\\n\"\n",
        "    \"Step 1: Think about how we can combine the 5's to form larger numbers (e.g., 55).\\n\"\n",
        "    \"Step 2: Try to combine them logically to reach 110.\\n\"\n",
        "    \"Now, provide the final equation and the answer.\"\n",
        ")\n",
        "\n",
        "# Run Zero-Shot\n",
        "response_zero = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": zero_shot_prompt}],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Run Chain-of-Thought\n",
        "response_cot = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": cot_prompt}],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Display Results\n",
        "print(\"üîπ Zero-Shot Response (No Reasoning Encouraged):\\n\" + \"-\" * 50)\n",
        "print(response_zero.choices[0].message.content.strip())\n",
        "\n",
        "print(\"\\nüîπ Chain-of-Thought Response (Reasoning Encouraged):\\n\" + \"-\" * 50)\n",
        "print(response_cot.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvcTsbGnveRU",
        "outputId": "b3a23e3e-8909-4a66-84d0-6622a38ccbe0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Zero-Shot Response (No Reasoning Encouraged):\n",
            "--------------------------------------------------\n",
            "(5 * 5) + (5 * 5) + 5 = 110\n",
            "\n",
            "üîπ Chain-of-Thought Response (Reasoning Encouraged):\n",
            "--------------------------------------------------\n",
            "Sure! Here's one way to reach 110 using five 5's:\n",
            "\n",
            "(5 * 5) + (5 * 5) + 5 = 110\n",
            "\n",
            "So, the final equation is (5 * 5) + (5 * 5) + 5 = 110, and the answer is 110.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chain-of-Thought Prompting Experiment Results\n",
        "\n",
        "**Model Used:** GPT-4-Turbo and GPT-3.5-Turbo  \n",
        "**Temperature Setting:** 0.0\n",
        "\n",
        "## Key Observations\n",
        "\n",
        "I ran experiments comparing zero-shot vs. chain-of-thought (CoT) prompting on two OpenAI models to solve the \"make 110 with five 5's\" problem. The results show interesting differences in reasoning capabilities and prompt responsiveness.\n",
        "\n",
        "GPT-3.5-Turbo produced identical solutions in both conditions: `(5 * 5) + (5 * 5) + 5 = 110`. Despite being prompted to show its work in the CoT condition, the model only added a brief introductory sentence before providing the same answer. This suggests limited benefit from explicit reasoning prompts with this model for this particular task.\n",
        "\n",
        "GPT-4-Turbo, however, demonstrated significant differences between conditions. In zero-shot, it provided `5 * (5 * 5 - 5) + 5 = 110` with a detailed breakdown of each step. In the CoT condition, it explored a completely different solution path, leading to `55 + 55 - 5 + 5 = 110` while explicitly tracking how it combined the digits.\n",
        "\n",
        "What's particularly interesting is that GPT-4 exhibited emergent reasoning abilities even without explicit prompting. It voluntarily provided step-by-step explanations in the zero-shot condition despite not being asked to show its work.\n",
        "\n",
        "The experiment highlights that model quality seems to be the primary factor in determining whether reasoning prompts are effective. For GPT-3.5, CoT prompting added minimal value, while for GPT-4, it encouraged exploration of alternative solution paths.\n",
        "\n",
        "These findings suggest that as models become more capable, they may benefit more from explicit reasoning prompts, though the strongest models might already employ reasoning internally regardless of prompting strategy."
      ],
      "metadata": {
        "id": "nQ5W2Fl6vrEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîÅ Self-Consistency Prompting\n",
        "\n",
        "While Chain-of-Thought (CoT) improves reasoning by encouraging step-by-step thinking, it may still produce **inconsistent or incorrect** answers, especially in complex scenarios.  \n",
        "**Self-Consistency Prompting** enhances CoT by asking the model to **generate multiple reasoning paths** and then select the most common or consistent final answer.\n",
        "\n",
        "### Why is Self-Consistency Useful?\n",
        "\n",
        "- ‚úÖ Reduces random reasoning errors.\n",
        "- ‚úÖ Boosts reliability on ambiguous or multi-path problems.\n",
        "- ‚úÖ Often improves performance on mathematical, logical, and symbolic tasks.\n",
        "\n",
        "üìñ **Reference**: [Self-Consistency Improves Chain of Thought Reasoning in Language Models](https://arxiv.org/abs/2203.11171)\n",
        "\n",
        "---\n",
        "\n",
        "*Next, we‚Äôll see how Self-Consistency works in action using a complex reasoning example.*\n"
      ],
      "metadata": {
        "id": "RN2Af6nAkKi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# üìå Comparing Chain-of-Thought vs. Self-Consistency Prompting\n",
        "# ==========================\n",
        "\n",
        "model_name = \"gpt-4-turbo\"  # Using GPT-4 for better reasoning\n",
        "\n",
        "# Define the problem prompt\n",
        "problem_prompt = (\n",
        "    \"If a train travels at 60 miles per hour and leaves at 2 PM, and another train leaves \"\n",
        "    \"the same station at 3 PM traveling at 90 miles per hour, when will the second train catch up to the first?\"\n",
        ")\n",
        "\n",
        "# Chain-of-Thought Prompt (Standard)\n",
        "cot_prompt = (\n",
        "    \"Let's solve this step by step.\\n\"\n",
        "    + problem_prompt\n",
        ")\n",
        "\n",
        "# Self-Consistency Prompt: Ask the model to produce multiple reasoning paths\n",
        "def run_self_consistency(prompt, num_attempts=5):\n",
        "    answers = []\n",
        "    for _ in range(num_attempts):\n",
        "        response = client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.7  # Add randomness to explore different reasoning paths\n",
        "        )\n",
        "        answer = response.choices[0].message.content.strip()\n",
        "        answers.append(answer)\n",
        "    return answers\n",
        "\n",
        "# Run Chain-of-Thought (Single Attempt)\n",
        "response_cot = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": cot_prompt}],\n",
        "    temperature=0\n",
        ")\n",
        "cot_answer = response_cot.choices[0].message.content.strip()\n",
        "\n",
        "# Run Self-Consistency (Multiple Attempts)\n",
        "sc_answers = run_self_consistency(cot_prompt, num_attempts=5)\n",
        "\n",
        "# Simple Majority Vote to Find Most Consistent Answer\n",
        "from collections import Counter\n",
        "most_common_answer = Counter(sc_answers).most_common(1)[0]\n",
        "\n",
        "# Display Results\n",
        "print(\"üîπ Chain-of-Thought Response (Single Attempt):\\n\" + \"-\" * 50)\n",
        "print(cot_answer)\n",
        "\n",
        "print(\"\\nüîπ Self-Consistency Responses (Multiple Attempts):\\n\" + \"-\" * 50)\n",
        "for idx, ans in enumerate(sc_answers, 1):\n",
        "    print(f\"Attempt {idx}: {ans}\")\n",
        "\n",
        "print(\"\\nüîπ Final Self-Consistency Selected Answer:\\n\" + \"-\" * 50)\n",
        "print(f\"Most Common Answer: {most_common_answer[0]}\\nAppeared {most_common_answer[1]} times.\")\n"
      ],
      "metadata": {
        "id": "yNWwXIahdaOX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84d93a9e-b313-45ab-a1f4-fd599f25453a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Chain-of-Thought Response (Single Attempt):\n",
            "--------------------------------------------------\n",
            "To find out when the second train will catch up to the first, we can start by calculating how far ahead the first train is when the second train starts.\n",
            "\n",
            "1. **Calculate the distance the first train travels in one hour:**\n",
            "   Since the first train leaves at 2 PM and travels at 60 miles per hour, by 3 PM (when the second train leaves), the first train will have traveled:\n",
            "   \\[\n",
            "   \\text{Distance} = \\text{Speed} \\times \\text{Time} = 60 \\text{ miles per hour} \\times 1 \\text{ hour} = 60 \\text{ miles}\n",
            "   \\]\n",
            "\n",
            "2. **Set up an equation to find when the second train catches up:**\n",
            "   Let \\( t \\) be the time in hours after 3 PM when the second train catches up to the first. At this time, both trains will have covered the same distance from the station.\n",
            "\n",
            "   - The first train's distance from the station at time \\( t \\) after 3 PM is:\n",
            "     \\[\n",
            "     \\text{Distance}_{\\text{first}} = 60 \\text{ miles} + 60 \\text{ miles per hour} \\times t\n",
            "     \\]\n",
            "   - The second train's distance from the station at time \\( t \\) after 3 PM is:\n",
            "     \\[\n",
            "     \\text{Distance}_{\\text{second}} = 90 \\text{ miles per hour} \\times t\n",
            "     \\]\n",
            "\n",
            "3. **Equating the distances and solving for \\( t \\):**\n",
            "   \\[\n",
            "   60 + 60t = 90t\n",
            "   \\]\n",
            "   Simplify and solve for \\( t \\):\n",
            "   \\[\n",
            "   60 = 90t - 60t\n",
            "   \\]\n",
            "   \\[\n",
            "   60 = 30t\n",
            "   \\]\n",
            "   \\[\n",
            "   t = \\frac{60}{30} = 2 \\text{ hours}\n",
            "   \\]\n",
            "\n",
            "4. **Determine the actual time of day when the second train catches up:**\n",
            "   Since \\( t = 2 \\) hours after 3 PM, the second train catches up at:\n",
            "   \\[\n",
            "   3 \\text{ PM} + 2 \\text{ hours} = 5 \\text{ PM}\n",
            "   \\]\n",
            "\n",
            "Therefore, the second train catches up to the first train at 5 PM.\n",
            "\n",
            "üîπ Self-Consistency Responses (Multiple Attempts):\n",
            "--------------------------------------------------\n",
            "Attempt 1: To find out when the second train will catch up to the first, we can use the concept of relative speed and the distances traveled by the trains.\n",
            "\n",
            "**Step 1: Calculate the distance covered by the first train when the second train starts.**\n",
            "Since the first train travels at 60 miles per hour, and it leaves at 2 PM, by the time the second train leaves at 3 PM, the first train would have traveled for 1 hour.\n",
            "\n",
            "\\[ \\text{Distance covered by first train in 1 hour} = 60 \\text{ miles per hour} \\times 1 \\text{ hour} = 60 \\text{ miles} \\]\n",
            "\n",
            "**Step 2: Determine the relative speed of the second train with respect to the first train.**\n",
            "The second train travels at 90 miles per hour, and the first train travels at 60 miles per hour. The relative speed of the second train with respect to the first is the difference in their speeds:\n",
            "\n",
            "\\[ \\text{Relative speed} = 90 \\text{ mph} - 60 \\text{ mph} = 30 \\text{ mph} \\]\n",
            "\n",
            "**Step 3: Calculate the time it will take for the second train to catch up.**\n",
            "The second train needs to cover the initial 60 miles gap between the two trains. Since the relative speed is 30 miles per hour, the time \\( t \\) required for the second train to catch up can be found using the formula for time:\n",
            "\n",
            "\\[ t = \\frac{\\text{Distance}}{\\text{Speed}} = \\frac{60 \\text{ miles}}{30 \\text{ mph}} = 2 \\text{ hours} \\]\n",
            "\n",
            "**Step 4: Determine the actual time of day when the second train catches up.**\n",
            "The second train leaves at 3 PM. If it takes 2 hours to catch up from 3 PM, it will catch up at:\n",
            "\n",
            "\\[ 3 \\text{ PM} + 2 \\text{ hours} = 5 \\text{ PM} \\]\n",
            "\n",
            "Thus, the second train will catch up to the first train at 5 PM.\n",
            "Attempt 2: To solve this problem, let's calculate the relative speeds and distances traveled by the two trains.\n",
            "\n",
            "1. **Speeds of the trains:**\n",
            "   - Train 1 speed = 60 mph\n",
            "   - Train 2 speed = 90 mph\n",
            "\n",
            "2. **Time difference in departure:**\n",
            "   - Train 1 leaves at 2 PM.\n",
            "   - Train 2 leaves at 3 PM, which is 1 hour later.\n",
            "\n",
            "3. **Distance traveled by Train 1 when Train 2 starts:**\n",
            "   Since Train 1 has a 1-hour head start and travels at 60 mph, the distance it covers in that hour is:\n",
            "   \\[\n",
            "   \\text{Distance} = \\text{Speed} \\times \\text{Time} = 60 \\text{ mph} \\times 1 \\text{ hour} = 60 \\text{ miles}\n",
            "   \\]\n",
            "\n",
            "4. **Relative speed of Train 2 compared to Train 1:**\n",
            "   Since Train 2 is catching up, we subtract the speed of Train 1 from the speed of Train 2:\n",
            "   \\[\n",
            "   \\text{Relative speed} = 90 \\text{ mph} - 60 \\text{ mph} = 30 \\text{ mph}\n",
            "   \\]\n",
            "\n",
            "5. **Time required for Train 2 to catch up:**\n",
            "   Train 2 needs to cover the initial 60 miles gap between them. At a relative speed of 30 mph, the time required to catch up is calculated as:\n",
            "   \\[\n",
            "   \\text{Time to catch up} = \\frac{\\text{Distance to catch up}}{\\text{Relative speed}} = \\frac{60 \\text{ miles}}{30 \\text{ mph}} = 2 \\text{ hours}\n",
            "   \\]\n",
            "\n",
            "6. **Time when Train 2 catches up:**\n",
            "   Since Train 2 leaves at 3 PM, adding the 2 hours it takes to catch up gives:\n",
            "   \\[\n",
            "   3 \\text{ PM} + 2 \\text{ hours} = 5 \\text{ PM}\n",
            "   \\]\n",
            "\n",
            "Therefore, Train 2 will catch up to Train 1 at 5 PM.\n",
            "Attempt 3: To solve this problem, we first need to determine how far the first train has traveled by the time the second train starts.\n",
            "\n",
            "1. **Calculate the distance traveled by the first train in one hour:**\n",
            "   - Speed of the first train = 60 miles per hour\n",
            "   - Time traveled before the second train starts = 1 hour (from 2 PM to 3 PM)\n",
            "   - Distance = Speed √ó Time = 60 miles/hour √ó 1 hour = 60 miles\n",
            "\n",
            "2. **Set up the equation to find when the second train catches up:**\n",
            "   - Let \\( t \\) be the time in hours after 3 PM when the second train catches up.\n",
            "   - Distance traveled by the first train by time \\( t \\) after 3 PM:\n",
            "     - It has already traveled 60 miles, and continues to travel at 60 mph.\n",
            "     - Total distance = 60 miles + 60 miles/hour √ó \\( t \\)\n",
            "   - Distance traveled by the second train by time \\( t \\) after 3 PM:\n",
            "     - It starts at 3 PM and travels at 90 mph.\n",
            "     - Total distance = 90 miles/hour √ó \\( t \\)\n",
            "\n",
            "3. **Equation for when distances are equal:**\n",
            "   - Set the distances equal to each other to find \\( t \\):\n",
            "     \\[\n",
            "     60 + 60t = 90t\n",
            "     \\]\n",
            "   - Simplify and solve for \\( t \\):\n",
            "     \\[\n",
            "     60 = 90t - 60t \\\\\n",
            "     60 = 30t \\\\\n",
            "     t = \\frac{60}{30} = 2 \\text{ hours}\n",
            "     \\]\n",
            "\n",
            "4. **Find the actual time when the second train catches up:**\n",
            "   - \\( t = 2 \\) hours after 3 PM\n",
            "   - 3 PM + 2 hours = 5 PM\n",
            "\n",
            "Thus, the second train catches up to the first train at 5 PM.\n",
            "Attempt 4: To solve this problem, we start by calculating how far the first train travels before the second train begins its journey. We then determine the rate at which the distance between the two trains closes, and use that to calculate when the second train catches up to the first.\n",
            "\n",
            "1. **Calculate the distance the first train travels in the first hour:**\n",
            "   - The first train travels at 60 miles per hour.\n",
            "   - In one hour (from 2 PM to 3 PM), the first train covers 60 miles.\n",
            "\n",
            "2. **Determine the relative speed of the two trains:**\n",
            "   - The second train travels at 90 miles per hour, and the first train travels at 60 miles per hour.\n",
            "   - The speed at which the distance between the two trains is closing is \\(90 - 60 = 30\\) miles per hour.\n",
            "\n",
            "3. **Calculate the time required for the second train to catch up:**\n",
            "   - The first train has a 60-mile head start.\n",
            "   - The second train closes the gap at a rate of 30 miles per hour.\n",
            "   - Time taken to catch up = Distance / Relative Speed = \\(60 \\text{ miles} / 30 \\text{ mph} = 2\\) hours.\n",
            "\n",
            "4. **Determine the catch-up time:**\n",
            "   - The second train leaves at 3 PM.\n",
            "   - It takes 2 hours to catch up.\n",
            "   - Therefore, the second train catches up to the first train at 3 PM + 2 hours = 5 PM.\n",
            "\n",
            "**Conclusion:**\n",
            "The second train catches up to the first train at 5 PM.\n",
            "Attempt 5: To find out when the second train will catch up to the first train, we start by calculating how far the first train travels by the time the second train departs.\n",
            "\n",
            "Given:\n",
            "- The speed of the first train = 60 miles per hour.\n",
            "- The first train departs at 2 PM.\n",
            "\n",
            "The second train departs:\n",
            "- At 3 PM.\n",
            "- The speed of the second train = 90 miles per hour.\n",
            "\n",
            "Time difference between the departures = 3 PM - 2 PM = 1 hour.\n",
            "\n",
            "In that 1 hour, the first train has traveled:\n",
            "Distance = Speed √ó Time = 60 miles per hour √ó 1 hour = 60 miles.\n",
            "\n",
            "Now, both trains are moving, and we need to calculate the time it takes for the second train to cover the 60-mile gap between it and the first train, and then catch up further.\n",
            "\n",
            "The speed difference between the two trains is:\n",
            "Speed difference = 90 miles per hour (second train) - 60 miles per hour (first train) = 30 miles per hour.\n",
            "\n",
            "This speed difference indicates how quickly the second train is catching up to the first train. The second train is catching up at a rate of 30 miles per hour.\n",
            "\n",
            "To find out how long it takes for the second train to catch up, we calculate the time to cover the 60-mile gap with the speed difference:\n",
            "Time = Distance / Speed difference = 60 miles / 30 miles per hour = 2 hours.\n",
            "\n",
            "Since the second train leaves at 3 PM, and it takes 2 hours to catch up to the first train, the time at which the second train catches up is:\n",
            "3 PM + 2 hours = 5 PM.\n",
            "\n",
            "Therefore, the second train catches up to the first train at 5 PM.\n",
            "\n",
            "üîπ Final Self-Consistency Selected Answer:\n",
            "--------------------------------------------------\n",
            "Most Common Answer: To find out when the second train will catch up to the first, we can use the concept of relative speed and the distances traveled by the trains.\n",
            "\n",
            "**Step 1: Calculate the distance covered by the first train when the second train starts.**\n",
            "Since the first train travels at 60 miles per hour, and it leaves at 2 PM, by the time the second train leaves at 3 PM, the first train would have traveled for 1 hour.\n",
            "\n",
            "\\[ \\text{Distance covered by first train in 1 hour} = 60 \\text{ miles per hour} \\times 1 \\text{ hour} = 60 \\text{ miles} \\]\n",
            "\n",
            "**Step 2: Determine the relative speed of the second train with respect to the first train.**\n",
            "The second train travels at 90 miles per hour, and the first train travels at 60 miles per hour. The relative speed of the second train with respect to the first is the difference in their speeds:\n",
            "\n",
            "\\[ \\text{Relative speed} = 90 \\text{ mph} - 60 \\text{ mph} = 30 \\text{ mph} \\]\n",
            "\n",
            "**Step 3: Calculate the time it will take for the second train to catch up.**\n",
            "The second train needs to cover the initial 60 miles gap between the two trains. Since the relative speed is 30 miles per hour, the time \\( t \\) required for the second train to catch up can be found using the formula for time:\n",
            "\n",
            "\\[ t = \\frac{\\text{Distance}}{\\text{Speed}} = \\frac{60 \\text{ miles}}{30 \\text{ mph}} = 2 \\text{ hours} \\]\n",
            "\n",
            "**Step 4: Determine the actual time of day when the second train catches up.**\n",
            "The second train leaves at 3 PM. If it takes 2 hours to catch up from 3 PM, it will catch up at:\n",
            "\n",
            "\\[ 3 \\text{ PM} + 2 \\text{ hours} = 5 \\text{ PM} \\]\n",
            "\n",
            "Thus, the second train will catch up to the first train at 5 PM.\n",
            "Appeared 1 times.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background: linear-gradient(135deg, #001a70 0%, #0055d4 100%); color: white; padding: 25px; border-radius: 12px; text-align: center;\">\n",
        "    <h1 style=\"margin-bottom: 10px;\">üìö Exploring More Advanced Prompting Strategies</h1>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4; margin-top: 20px;\">\n",
        "    <ul style=\"font-size: 16px; line-height: 1.8;\">\n",
        "        <li><strong>üß© Tree-of-Thought (ToT) Prompting:</strong> Explores multiple reasoning paths like a decision tree, helping the model evaluate and compare various solutions before choosing the best one.</li>\n",
        "        <li><strong>ü§ñ ReAct (Reasoning and Acting) Prompting:</strong> Combines reasoning steps with actions, including API calls or external tool usage. Ideal for interactive agents and dynamic decision-making tasks.</li>\n",
        "        <li><strong>üîÑ Reflexion Prompting:</strong> Encourages the model to critique its own responses and iteratively improve them, simulating self-correction and learning.</li>\n",
        "    </ul>\n",
        "</div>\n",
        "\n",
        "<div style=\"margin-top: 40px; text-align: center;\">\n",
        "    <h2 style=\"color: #001a70;\">‚úã Hands-On Task: Compare Prompting Strategies</h2>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #f5faff; padding: 20px; border-radius: 8px; border-left: 5px solid #0055d4;\">\n",
        "    <p style=\"font-size: 16px;\">\n",
        "        üìå <strong>Task Instructions:</strong><br>\n",
        "        - Experiment with <strong>Self-Consistency</strong>, <strong>Tree-of-Thought</strong>, and <strong>ReAct</strong> prompting methods.<br>\n",
        "        - Try to solve the following problem using each method and compare the results.\n",
        "    </p>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4; margin-top: 20px;\">\n",
        "    <h3>üß† <strong>Challenge Problem:</strong></h3>\n",
        "    <p style=\"font-size: 16px;\">A farmer has chickens and rabbits in a cage. There are 35 heads and 94 legs. How many chickens and rabbits are there?</p>\n",
        "</div>\n",
        "\n",
        "<div style=\"margin-top: 40px;\">\n",
        "    <ul style=\"font-size: 16px; line-height: 1.8;\">\n",
        "        <li>Try different models (e.g., <code>gpt-3.5-turbo</code>, <code>gpt-4-turbo</code>, <code>gpt-o3</code>).</li>\n",
        "        <li>Experiment with different temperatures (e.g., <code>0.0</code>, <code>0.5</code>, <code>0.7</code>).</li>\n",
        "        <li>Use both direct prompts and advanced strategies like CoT, Self-Consistency, or ReAct.</li>\n",
        "    </ul>\n",
        "</div>\n",
        "\n",
        "<div style=\"margin-top: 40px; text-align: center;\">\n",
        "    <h2 style=\"color: #001a70;\">üìñ Observations</h2>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4;\">\n",
        "   <div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4;\">\n",
        "    <ul style=\"font-size: 16px; line-height: 1.8;\">\n",
        "        <li><strong>Model and Strategy Used:</strong><br>I compared GPT-3.5-Turbo and GPT-4-Turbo using four different prompting strategies (Chain-of-Thought, Tree-of-Thought, ReAct, and Self-Consistency) with varying temperature settings (0.0, 0.7, 0.5, and 0.7 respectively).</li>\n",
        "        <li><strong>Was the Correct Answer Found?</strong><br>Yes. Both models achieved 100% accuracy across all four prompting strategies, correctly identifying that there are 23 chickens and 12 rabbits.</li>\n",
        "        <li><strong>Key Takeaways:</strong><br>\n",
        "            <ol>\n",
        "                <li><strong>Reasoning Style Differences:</strong> Despite identical accuracy, GPT-4-Turbo demonstrated more structured reasoning with formal mathematical notation (using variables and equation systems), while GPT-3.5-Turbo used more straightforward arithmetic approaches.</li>\n",
        "                <li><strong>Temperature Effects:</strong> The higher temperature (0.7) for Tree-of-Thought prompting encouraged both models to explore multiple solution paths simultaneously, demonstrating more diverse problem-solving approaches compared to the deterministic Chain-of-Thought (temperature 0.0).</li>\n",
        "                <li><strong>Strategy Effectiveness:</strong> For this well-defined algebraic problem, even simpler prompting strategies like Chain-of-Thought proved sufficient. The more complex Tree-of-Thought strategy showed its potential by systematically exploring three different solution methods (algebraic, trial-and-error, and working backward), though this added complexity didn't improve accuracy for this particular problem.</li>\n",
        "                <li><strong>Self-Consistency Robustness:</strong> Both models showed perfect consistency (100%) when generating multiple solutions with higher temperature, suggesting that for straightforward mathematical problems, the underlying reasoning capabilities are stable even with randomness introduced.</li>\n",
        "                <li><strong>ReAct Structure:</strong> The ReAct prompting format (at temperature 0.5) enforced a more rigorous thought-action-observation cycle that made reasoning steps more explicit, which could be beneficial for teaching purposes or explaining complex problem-solving processes.</li>\n",
        "            </ol>\n",
        "        </li>\n",
        "    </ul>\n",
        "</div>\n",
        "</div>\n",
        "\n",
        "<div style=\"margin-top: 20px; text-align: center;\">\n",
        "    ‚úçÔ∏è <em>Hint: Try breaking down the problem into equations or ask the model to explain its steps before giving the final answer. Notice which strategies lead to faster and more accurate results!</em>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "Hfw5kDf5l_o_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# ‚úã Hands-On Code: Try Different Prompting Strategies and Models\n",
        "# ==========================\n",
        "\n",
        "# üìù Instructions:\n",
        "# - Change 'model_name' to try different models (e.g., \"gpt-3.5-turbo\", \"gpt-4-turbo\", \"gpt-o3\").\n",
        "# - Adjust 'temperature' to test how creativity affects reasoning.\n",
        "# - Try Self-Consistency by sampling multiple outputs and comparing answers.\n",
        "# - Optionally, explore Tree-of-Thought and ReAct patterns by modifying prompts.\n",
        "# ‚úÖ Your Experiment Starts Here üëá\n",
        "\n",
        "# ==========================\n",
        "# üìå Comparing Advanced Prompting Strategies for the Chickens and Rabbits Problem\n",
        "# ==========================\n",
        "\n",
        "# We'll test multiple models and strategies and compare results\n",
        "models_to_test = [\"gpt-3.5-turbo\", \"gpt-4-turbo\"]  # Add \"gpt-o3\" if you have access\n",
        "\n",
        "# Define the problem prompt\n",
        "problem = (\n",
        "    \"A farmer has chickens and rabbits in a cage. There are 35 heads and 94 legs. \"\n",
        "    \"How many chickens and rabbits are there?\"\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# Chain-of-Thought (CoT) Prompt\n",
        "# -------------------------\n",
        "cot_prompt = (\n",
        "    f\"Problem: {problem}\\n\\n\"\n",
        "    \"Let's solve this step by step:\\n\\n\"\n",
        "    \"1) Let's define variables: Let c be the number of chickens and r be the number of rabbits.\\n\"\n",
        "    \"2) Write equations based on the given information.\\n\"\n",
        "    \"3) Solve the system of equations.\\n\"\n",
        "    \"4) Verify the answer.\"\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# Tree-of-Thought (ToT) Prompt\n",
        "# -------------------------\n",
        "tot_prompt = (\n",
        "    f\"Problem: {problem}\\n\\n\"\n",
        "    \"Let's explore multiple solution paths and compare them to find the most reliable answer:\\n\\n\"\n",
        "    \"Path 1: Algebraic Solution\\n\"\n",
        "    \"- Define variables for chickens and rabbits\\n\"\n",
        "    \"- Set up equations for heads and legs\\n\"\n",
        "    \"- Solve the system of equations\\n\\n\"\n",
        "\n",
        "    \"Path 2: Trial and Error with Constraints\\n\"\n",
        "    \"- Total heads = 35, so possible combinations must sum to 35\\n\"\n",
        "    \"- For each combination, calculate total legs and check against 94\\n\"\n",
        "    \"- Find the combination that matches exactly\\n\\n\"\n",
        "\n",
        "    \"Path 3: Working Backward from Legs\\n\"\n",
        "    \"- If all animals were chickens (2 legs each), we would have 70 legs\\n\"\n",
        "    \"- The extra legs (94 - 70 = 24) must come from rabbits having 2 more legs than chickens\\n\"\n",
        "    \"- Calculate how many rabbits based on extra legs\\n\\n\"\n",
        "\n",
        "    \"Explore each path and determine which one leads to the correct answer. For each path, show your work, \"\n",
        "    \"note any potential errors, and state your confidence in the result.\\n\\n\"\n",
        "    \"Finally, compare the results from all paths and determine the final answer.\"\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# ReAct (Reasoning + Acting) Prompt\n",
        "# -------------------------\n",
        "react_prompt = (\n",
        "    f\"Problem: {problem}\\n\\n\"\n",
        "    \"Solve this problem using the ReAct format (Reasoning + Acting). Follow this structured approach:\\n\\n\"\n",
        "    \"Thought: [Describe your thinking about how to approach the problem]\\n\"\n",
        "    \"Action: [Define a specific step to take]\\n\"\n",
        "    \"Observation: [Note what you observe after taking that step]\\n\\n\"\n",
        "\n",
        "    \"Continue this Thought-Action-Observation cycle until you solve the problem. \"\n",
        "    \"Be explicit about each equation you write and each calculation you perform. \"\n",
        "    \"If you make a mistake, acknowledge it and correct yourself in the next cycle.\"\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# Self-Consistency Implementation\n",
        "# -------------------------\n",
        "def run_self_consistency(prompt, num_attempts=5, temperature=0.7):\n",
        "    answers = []\n",
        "    responses = []\n",
        "\n",
        "    for _ in range(num_attempts):\n",
        "        response = client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=temperature  # Add randomness to explore different reasoning paths\n",
        "        )\n",
        "\n",
        "        full_response = response.choices[0].message.content.strip()\n",
        "        responses.append(full_response)\n",
        "\n",
        "        # Extract final answer - look for patterns like \"answer is X chickens and Y rabbits\"\n",
        "        import re\n",
        "        answer_match = re.search(r\"(\\d+)\\s+chickens\\s+and\\s+(\\d+)\\s+rabbits\", full_response, re.IGNORECASE)\n",
        "        if answer_match:\n",
        "            chickens, rabbits = int(answer_match.group(1)), int(answer_match.group(2))\n",
        "            answers.append((chickens, rabbits))\n",
        "\n",
        "    # Find most common answer\n",
        "    from collections import Counter\n",
        "    if answers:\n",
        "        most_common_answer = Counter(answers).most_common(1)[0]\n",
        "        return {\n",
        "            \"responses\": responses,\n",
        "            \"answer_counts\": Counter(answers),\n",
        "            \"most_common\": most_common_answer\n",
        "        }\n",
        "    else:\n",
        "        return {\n",
        "            \"responses\": responses,\n",
        "            \"answer_counts\": {},\n",
        "            \"most_common\": None\n",
        "        }\n",
        "\n",
        "# -------------------------\n",
        "# Result Storage\n",
        "# -------------------------\n",
        "results = {\n",
        "    model: {\n",
        "        \"cot\": None,\n",
        "        \"tot\": None,\n",
        "        \"react\": None,\n",
        "        \"self_consistency\": None\n",
        "    }\n",
        "    for model in models_to_test\n",
        "}\n",
        "\n",
        "# -------------------------\n",
        "# Run Experiments\n",
        "# -------------------------\n",
        "for model_name in models_to_test:\n",
        "    print(f\"\\n\\n{'='*50}\")\n",
        "    print(f\"TESTING MODEL: {model_name}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    # Chain of Thought (Single attempt)\n",
        "    print(f\"Running Chain of Thought experiment with {model_name}...\")\n",
        "    response_cot = client.chat.completions.create(\n",
        "        model=model_name,\n",
        "        messages=[{\"role\": \"user\", \"content\": cot_prompt}],\n",
        "        temperature=0.0\n",
        "    )\n",
        "    results[model_name][\"cot\"] = response_cot.choices[0].message.content.strip()\n",
        "\n",
        "    # Tree of Thought (Single attempt)\n",
        "    print(f\"Running Tree of Thought experiment with {model_name}...\")\n",
        "    response_tot = client.chat.completions.create(\n",
        "        model=model_name,\n",
        "        messages=[{\"role\": \"user\", \"content\": tot_prompt}],\n",
        "        temperature=0.7\n",
        "    )\n",
        "    results[model_name][\"tot\"] = response_tot.choices[0].message.content.strip()\n",
        "\n",
        "    # ReAct (Single attempt)\n",
        "    print(f\"Running ReAct experiment with {model_name}...\")\n",
        "    response_react = client.chat.completions.create(\n",
        "        model=model_name,\n",
        "        messages=[{\"role\": \"user\", \"content\": react_prompt}],\n",
        "        temperature=0.5\n",
        "    )\n",
        "    results[model_name][\"react\"] = response_react.choices[0].message.content.strip()\n",
        "\n",
        "    # Self-Consistency (with CoT prompt)\n",
        "    print(f\"Running Self-Consistency experiment with {model_name}...\")\n",
        "    sc_results = run_self_consistency(cot_prompt, num_attempts=3, temperature=0.7)  # Reduced to 3 attempts to save tokens\n",
        "    results[model_name][\"self_consistency\"] = sc_results\n",
        "\n",
        "# -------------------------\n",
        "# Analysis Helper Functions\n",
        "# -------------------------\n",
        "def extract_answer(text):\n",
        "    \"\"\"Extracts the chicken and rabbit counts from the response text.\"\"\"\n",
        "    import re\n",
        "    answer_match = re.search(r\"(\\d+)\\s+chickens\\s+and\\s+(\\d+)\\s+rabbits\", text, re.IGNORECASE)\n",
        "    if answer_match:\n",
        "        return (int(answer_match.group(1)), int(answer_match.group(2)))\n",
        "    return None\n",
        "\n",
        "def is_correct(answer):\n",
        "    \"\"\"Checks if the extracted answer is correct (23 chickens and 12 rabbits).\"\"\"\n",
        "    return answer == (23, 12)\n",
        "\n",
        "def analyze_results(results):\n",
        "    \"\"\"Analyzes the results from all experiments and creates a summary.\"\"\"\n",
        "    summary = {}\n",
        "\n",
        "    for model in results:\n",
        "        summary[model] = {\n",
        "            \"cot\": {\"answer\": extract_answer(results[model][\"cot\"]), \"correct\": False},\n",
        "            \"tot\": {\"answer\": extract_answer(results[model][\"tot\"]), \"correct\": False},\n",
        "            \"react\": {\"answer\": extract_answer(results[model][\"react\"]), \"correct\": False},\n",
        "            \"self_consistency\": {\"answer\": None, \"correct\": False, \"consistency\": 0}\n",
        "        }\n",
        "\n",
        "        # Check correctness\n",
        "        if summary[model][\"cot\"][\"answer\"]:\n",
        "            summary[model][\"cot\"][\"correct\"] = is_correct(summary[model][\"cot\"][\"answer\"])\n",
        "\n",
        "        if summary[model][\"tot\"][\"answer\"]:\n",
        "            summary[model][\"tot\"][\"correct\"] = is_correct(summary[model][\"tot\"][\"answer\"])\n",
        "\n",
        "        if summary[model][\"react\"][\"answer\"]:\n",
        "            summary[model][\"react\"][\"correct\"] = is_correct(summary[model][\"react\"][\"answer\"])\n",
        "\n",
        "        # Handle self-consistency\n",
        "        sc_data = results[model][\"self_consistency\"]\n",
        "        if sc_data[\"most_common\"]:\n",
        "            answer, count = sc_data[\"most_common\"]\n",
        "            total = sum(sc_data[\"answer_counts\"].values())\n",
        "            summary[model][\"self_consistency\"][\"answer\"] = answer\n",
        "            summary[model][\"self_consistency\"][\"correct\"] = is_correct(answer)\n",
        "            summary[model][\"self_consistency\"][\"consistency\"] = count / total\n",
        "\n",
        "    return summary\n",
        "\n",
        "# -------------------------\n",
        "# Performance Analysis\n",
        "# -------------------------\n",
        "def analyze_performance(summary):\n",
        "    \"\"\"Generate performance metrics for each model and strategy.\"\"\"\n",
        "\n",
        "    metrics = {\n",
        "        \"model_performance\": {},\n",
        "        \"strategy_performance\": {\n",
        "            \"cot\": {\"correct\": 0, \"total\": 0},\n",
        "            \"tot\": {\"correct\": 0, \"total\": 0},\n",
        "            \"react\": {\"correct\": 0, \"total\": 0},\n",
        "            \"self_consistency\": {\"correct\": 0, \"total\": 0}\n",
        "        },\n",
        "        \"overall_best\": {\"model\": None, \"strategy\": None, \"score\": 0}\n",
        "    }\n",
        "\n",
        "    # Calculate model performance\n",
        "    for model in summary:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for strategy in summary[model]:\n",
        "            if summary[model][strategy][\"correct\"]:\n",
        "                correct += 1\n",
        "            total += 1\n",
        "\n",
        "            # Update strategy performance\n",
        "            if summary[model][strategy][\"correct\"]:\n",
        "                metrics[\"strategy_performance\"][strategy][\"correct\"] += 1\n",
        "            metrics[\"strategy_performance\"][strategy][\"total\"] += 1\n",
        "\n",
        "        metrics[\"model_performance\"][model] = {\n",
        "            \"correct\": correct,\n",
        "            \"total\": total,\n",
        "            \"accuracy\": correct / total if total > 0 else 0\n",
        "        }\n",
        "\n",
        "        # Check if this is the best model so far\n",
        "        if correct > metrics[\"overall_best\"][\"score\"]:\n",
        "            metrics[\"overall_best\"][\"model\"] = model\n",
        "            metrics[\"overall_best\"][\"score\"] = correct\n",
        "\n",
        "    # Calculate strategy performance percentages\n",
        "    for strategy in metrics[\"strategy_performance\"]:\n",
        "        strategy_data = metrics[\"strategy_performance\"][strategy]\n",
        "        strategy_data[\"accuracy\"] = strategy_data[\"correct\"] / strategy_data[\"total\"] if strategy_data[\"total\"] > 0 else 0\n",
        "\n",
        "        # Check if this is the best strategy so far\n",
        "        if strategy_data[\"accuracy\"] > metrics[\"overall_best\"].get(\"strategy_score\", 0):\n",
        "            metrics[\"overall_best\"][\"strategy\"] = strategy\n",
        "            metrics[\"overall_best\"][\"strategy_score\"] = strategy_data[\"accuracy\"]\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# Visualize results (optional - requires matplotlib)\n",
        "def visualize_results(summary, metrics):\n",
        "    \"\"\"Create visualizations of the results.\"\"\"\n",
        "    try:\n",
        "        import matplotlib.pyplot as plt\n",
        "        import numpy as np\n",
        "\n",
        "        # Set up the figure and axes\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "        # Model performance bar chart\n",
        "        models = list(metrics[\"model_performance\"].keys())\n",
        "        accuracies = [metrics[\"model_performance\"][model][\"accuracy\"] * 100 for model in models]\n",
        "\n",
        "        ax1.bar(models, accuracies)\n",
        "        ax1.set_ylim(0, 100)\n",
        "        ax1.set_ylabel(\"Accuracy (%)\")\n",
        "        ax1.set_title(\"Model Performance\")\n",
        "\n",
        "        # Strategy performance bar chart\n",
        "        strategies = list(metrics[\"strategy_performance\"].keys())\n",
        "        strategy_accuracies = [metrics[\"strategy_performance\"][strategy][\"accuracy\"] * 100 for strategy in strategies]\n",
        "\n",
        "        ax2.bar(strategies, strategy_accuracies)\n",
        "        ax2.set_ylim(0, 100)\n",
        "        ax2.set_ylabel(\"Accuracy (%)\")\n",
        "        ax2.set_title(\"Strategy Performance\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"prompting_strategy_results.png\")\n",
        "        print(\"\\nVisualization saved as 'prompting_strategy_results.png'\")\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"\\nMatplotlib not available. Skipping visualization.\")\n",
        "\n",
        "# -------------------------\n",
        "# Display Results\n",
        "# -------------------------\n",
        "print(\"\\n\\n\" + \"=\"*80)\n",
        "print(\"RESULTS SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "summary = analyze_results(results)\n",
        "performance = analyze_performance(summary)\n",
        "\n",
        "# Create a comparison table\n",
        "from tabulate import tabulate\n",
        "\n",
        "table_data = []\n",
        "headers = [\"Model\", \"Strategy\", \"Answer\", \"Correct?\", \"Notes\"]\n",
        "\n",
        "for model in summary:\n",
        "    for strategy in [\"cot\", \"tot\", \"react\", \"self_consistency\"]:\n",
        "        result = summary[model][strategy]\n",
        "\n",
        "        if strategy == \"self_consistency\":\n",
        "            answer_str = f\"{result['answer'][0]} chickens, {result['answer'][1]} rabbits\" if result['answer'] else \"No consistent answer\"\n",
        "            notes = f\"Consistency: {result['consistency']*100:.1f}%\" if result['answer'] else \"N/A\"\n",
        "        else:\n",
        "            answer_str = f\"{result['answer'][0]} chickens, {result['answer'][1]} rabbits\" if result['answer'] else \"Couldn't extract answer\"\n",
        "            notes = \"\"\n",
        "\n",
        "        table_data.append([\n",
        "            model,\n",
        "            strategy.upper(),\n",
        "            answer_str,\n",
        "            \"‚úì\" if result[\"correct\"] else \"‚úó\",\n",
        "            notes\n",
        "        ])\n",
        "\n",
        "print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
        "\n",
        "# Print performance summary\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PERFORMANCE SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Model performance\n",
        "print(\"\\nModel Performance:\")\n",
        "for model, perf in performance[\"model_performance\"].items():\n",
        "    print(f\"- {model}: {perf['correct']}/{perf['total']} correct ({perf['accuracy']*100:.1f}%)\")\n",
        "\n",
        "# Strategy performance\n",
        "print(\"\\nStrategy Performance:\")\n",
        "for strategy, perf in performance[\"strategy_performance\"].items():\n",
        "    print(f\"- {strategy.upper()}: {perf['correct']}/{perf['total']} correct ({perf['accuracy']*100:.1f}%)\")\n",
        "\n",
        "# Best overall\n",
        "print(f\"\\nBest Model: {performance['overall_best']['model']}\")\n",
        "print(f\"Best Strategy: {performance['overall_best']['strategy'].upper()}\")\n",
        "\n",
        "# Create visualization (optional)\n",
        "try:\n",
        "    visualize_results(summary, performance)\n",
        "except Exception as e:\n",
        "    print(f\"\\nVisualization error: {e}\")\n",
        "\n",
        "# -------------------------\n",
        "# Print Detailed Results (Optional)\n",
        "# -------------------------\n",
        "print_details = False  # Set to True if you want to see the full responses\n",
        "\n",
        "if print_details:\n",
        "    for model in results:\n",
        "        print(f\"\\n\\n{'='*50}\")\n",
        "        print(f\"DETAILED RESULTS FOR {model}\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "        print(\"\\nüîπ Chain-of-Thought Response:\\n\" + \"-\" * 50)\n",
        "        print(results[model][\"cot\"])\n",
        "\n",
        "        print(\"\\nüîπ Tree-of-Thought Response:\\n\" + \"-\" * 50)\n",
        "        print(results[model][\"tot\"])\n",
        "\n",
        "        print(\"\\nüîπ ReAct Response:\\n\" + \"-\" * 50)\n",
        "        print(results[model][\"react\"])\n",
        "\n",
        "        print(\"\\nüîπ Self-Consistency Results:\\n\" + \"-\" * 50)\n",
        "        sc_results = results[model][\"self_consistency\"]\n",
        "        if sc_results[\"most_common\"]:\n",
        "            answer, count = sc_results[\"most_common\"]\n",
        "            print(f\"Most Common Answer: {answer[0]} chickens and {answer[1]} rabbits\")\n",
        "            print(f\"This answer appeared {count} out of {len(sc_results['responses'])} times\")\n",
        "\n",
        "            print(\"\\nAnswer Distribution:\")\n",
        "            for answer, count in sc_results[\"answer_counts\"].items():\n",
        "                print(f\"- {answer[0]} chickens and {answer[1]} rabbits: {count} times\")\n",
        "        else:\n",
        "            print(\"No consistent answers found\")\n"
      ],
      "metadata": {
        "id": "5kYqO4FgkJd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f3add78b-67b0-44f3-8ca1-bc3980d18f10"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "==================================================\n",
            "TESTING MODEL: gpt-3.5-turbo\n",
            "==================================================\n",
            "Running Chain of Thought experiment with gpt-3.5-turbo...\n",
            "Running Tree of Thought experiment with gpt-3.5-turbo...\n",
            "Running ReAct experiment with gpt-3.5-turbo...\n",
            "Running Self-Consistency experiment with gpt-3.5-turbo...\n",
            "\n",
            "\n",
            "==================================================\n",
            "TESTING MODEL: gpt-4-turbo\n",
            "==================================================\n",
            "Running Chain of Thought experiment with gpt-4-turbo...\n",
            "Running Tree of Thought experiment with gpt-4-turbo...\n",
            "Running ReAct experiment with gpt-4-turbo...\n",
            "Running Self-Consistency experiment with gpt-4-turbo...\n",
            "\n",
            "\n",
            "================================================================================\n",
            "RESULTS SUMMARY\n",
            "================================================================================\n",
            "+---------------+------------------+-------------------------+------------+---------------------+\n",
            "| Model         | Strategy         | Answer                  | Correct?   | Notes               |\n",
            "+===============+==================+=========================+============+=====================+\n",
            "| gpt-3.5-turbo | COT              | 23 chickens, 12 rabbits | ‚úì          |                     |\n",
            "+---------------+------------------+-------------------------+------------+---------------------+\n",
            "| gpt-3.5-turbo | TOT              | 23 chickens, 12 rabbits | ‚úì          |                     |\n",
            "+---------------+------------------+-------------------------+------------+---------------------+\n",
            "| gpt-3.5-turbo | REACT            | 23 chickens, 12 rabbits | ‚úì          |                     |\n",
            "+---------------+------------------+-------------------------+------------+---------------------+\n",
            "| gpt-3.5-turbo | SELF_CONSISTENCY | 23 chickens, 12 rabbits | ‚úì          | Consistency: 100.0% |\n",
            "+---------------+------------------+-------------------------+------------+---------------------+\n",
            "| gpt-4-turbo   | COT              | 23 chickens, 12 rabbits | ‚úì          |                     |\n",
            "+---------------+------------------+-------------------------+------------+---------------------+\n",
            "| gpt-4-turbo   | TOT              | 23 chickens, 12 rabbits | ‚úì          |                     |\n",
            "+---------------+------------------+-------------------------+------------+---------------------+\n",
            "| gpt-4-turbo   | REACT            | 23 chickens, 12 rabbits | ‚úì          |                     |\n",
            "+---------------+------------------+-------------------------+------------+---------------------+\n",
            "| gpt-4-turbo   | SELF_CONSISTENCY | 23 chickens, 12 rabbits | ‚úì          | Consistency: 100.0% |\n",
            "+---------------+------------------+-------------------------+------------+---------------------+\n",
            "\n",
            "================================================================================\n",
            "PERFORMANCE SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Model Performance:\n",
            "- gpt-3.5-turbo: 4/4 correct (100.0%)\n",
            "- gpt-4-turbo: 4/4 correct (100.0%)\n",
            "\n",
            "Strategy Performance:\n",
            "- COT: 2/2 correct (100.0%)\n",
            "- TOT: 2/2 correct (100.0%)\n",
            "- REACT: 2/2 correct (100.0%)\n",
            "- SELF_CONSISTENCY: 2/2 correct (100.0%)\n",
            "\n",
            "Best Model: gpt-3.5-turbo\n",
            "Best Strategy: COT\n",
            "\n",
            "Visualization saved as 'prompting_strategy_results.png'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View full model responses for each strategy with temperature information\n",
        "print_details = True  # Set to True to see the full responses from each model and strategy\n",
        "\n",
        "if print_details:\n",
        "    # First, define a helper function to show limited response text\n",
        "    def show_truncated_response(text, max_length=1500):\n",
        "        \"\"\"Shows a truncated version of a response with ellipsis if too long\"\"\"\n",
        "        if len(text) > max_length:\n",
        "            return text[:max_length] + \"...\\n[Response truncated for readability]\"\n",
        "        return text\n",
        "\n",
        "    # Define the temperature settings used for each strategy\n",
        "    temperature_settings = {\n",
        "        \"cot\": 0.0,\n",
        "        \"tot\": 0.7,\n",
        "        \"react\": 0.5,\n",
        "        \"self_consistency\": 0.7\n",
        "    }\n",
        "\n",
        "    # Display model responses with temperature information\n",
        "    for model in models_to_test:\n",
        "        print(f\"\\n\\n{'='*80}\")\n",
        "        print(f\"DETAILED RESULTS FOR {model.upper()}\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        print(f\"\\nüîπ Chain-of-Thought Response (Temperature: {temperature_settings['cot']}):\\n\" + \"-\" * 50)\n",
        "        print(show_truncated_response(results[model][\"cot\"]))\n",
        "\n",
        "        print(f\"\\nüîπ Tree-of-Thought Response (Temperature: {temperature_settings['tot']}):\\n\" + \"-\" * 50)\n",
        "        print(show_truncated_response(results[model][\"tot\"]))\n",
        "\n",
        "        print(f\"\\nüîπ ReAct Response (Temperature: {temperature_settings['react']}):\\n\" + \"-\" * 50)\n",
        "        print(show_truncated_response(results[model][\"react\"]))\n",
        "\n",
        "        # Self-Consistency Results\n",
        "        print(f\"\\n\\n{'='*80}\")\n",
        "        print(f\"SELF-CONSISTENCY RESULTS FOR {model.upper()} (Temperature: {temperature_settings['self_consistency']})\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        sc_results = results[model][\"self_consistency\"]\n",
        "        if sc_results[\"most_common\"]:\n",
        "            answer, count = sc_results[\"most_common\"]\n",
        "            print(f\"Most Common Answer: {answer[0]} chickens and {answer[1]} rabbits\")\n",
        "            print(f\"This answer appeared {count} out of {len(sc_results['responses'])} times\")\n",
        "\n",
        "            print(\"\\nAnswer Distribution:\")\n",
        "            for answer, count in sc_results[\"answer_counts\"].items():\n",
        "                print(f\"- {answer[0]} chickens and {answer[1]} rabbits: {count} times\")\n",
        "\n",
        "            print(\"\\nSample Response:\")\n",
        "            print(show_truncated_response(sc_results[\"responses\"][0]))\n",
        "        else:\n",
        "            print(\"No consistent answers found\")\n",
        "\n",
        "    # Add a section summarizing temperature impact\n",
        "    print(f\"\\n\\n{'='*80}\")\n",
        "    print(f\"TEMPERATURE SETTINGS SUMMARY\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(\"The following temperature settings were used for each prompting strategy:\")\n",
        "\n",
        "    for strategy, temp in temperature_settings.items():\n",
        "        print(f\"- {strategy.upper()}: {temp}\")\n",
        "\n",
        "    print(\"\\nImpact of Temperature Settings:\")\n",
        "    print(\"- Lower temperature (0.0) for Chain-of-Thought: More deterministic reasoning, consistent solution paths\")\n",
        "    print(\"- Higher temperature (0.7) for Tree-of-Thought: Encourages exploration of multiple solution paths\")\n",
        "    print(\"- Medium temperature (0.5) for ReAct: Balance between creativity and structure in reasoning steps\")\n",
        "    print(\"- Higher temperature (0.7) for Self-Consistency: Generates diverse reasoning attempts to find consensus\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-RJEH71zPHy",
        "outputId": "b515d717-c043-4570-b15d-07a1715000a2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "================================================================================\n",
            "DETAILED RESULTS FOR GPT-3.5-TURBO\n",
            "================================================================================\n",
            "\n",
            "üîπ Chain-of-Thought Response (Temperature: 0.0):\n",
            "--------------------------------------------------\n",
            "1) Let c be the number of chickens and r be the number of rabbits.\n",
            "\n",
            "2) We know that:\n",
            "- The total number of heads is 35: c + r = 35\n",
            "- The total number of legs is 94: 2c + 4r = 94\n",
            "\n",
            "3) Solve the system of equations:\n",
            "From the first equation, we can express c in terms of r:\n",
            "c = 35 - r\n",
            "\n",
            "Substitute c in the second equation:\n",
            "2(35 - r) + 4r = 94\n",
            "70 - 2r + 4r = 94\n",
            "2r = 24\n",
            "r = 12\n",
            "\n",
            "Now, substitute r back into c = 35 - r:\n",
            "c = 35 - 12\n",
            "c = 23\n",
            "\n",
            "So, there are 23 chickens and 12 rabbits in the cage.\n",
            "\n",
            "4) Verify the answer:\n",
            "23 chickens have 23 * 2 = 46 legs\n",
            "12 rabbits have 12 * 4 = 48 legs\n",
            "Total legs = 46 + 48 = 94 legs\n",
            "\n",
            "The total number of heads is 23 + 12 = 35\n",
            "\n",
            "Therefore, the solution is correct.\n",
            "\n",
            "üîπ Tree-of-Thought Response (Temperature: 0.7):\n",
            "--------------------------------------------------\n",
            "Path 1: Algebraic Solution\n",
            "\n",
            "Let x be the number of chickens and y be the number of rabbits.\n",
            "\n",
            "From the given information:\n",
            "x + y = 35 (total heads)\n",
            "2x + 4y = 94 (total legs)\n",
            "\n",
            "Solving the system of equations:\n",
            "x = 35 - y\n",
            "2(35 - y) + 4y = 94\n",
            "70 - 2y + 4y = 94\n",
            "2y = 24\n",
            "y = 12\n",
            "\n",
            "Substitute y = 12 back into x + y = 35:\n",
            "x + 12 = 35\n",
            "x = 23\n",
            "\n",
            "There are 23 chickens and 12 rabbits.\n",
            "\n",
            "Confidence Level: High\n",
            "\n",
            "---\n",
            "\n",
            "Path 2: Trial and Error with Constraints\n",
            "\n",
            "Starting with a trial and error approach, we can test combinations of chickens and rabbits that add up to 35 heads and check if the total legs match 94.\n",
            "\n",
            "Let's test a combination:\n",
            "Chickens: 1, Rabbits: 34 (1 * 2 + 34 * 4 = 138, which is more than 94)\n",
            "Chickens: 2, Rabbits: 33 (2 * 2 + 33 * 4 = 134, which is less than 94)\n",
            "Chickens: 3, Rabbits: 32 (3 * 2 + 32 * 4 = 130, which is less than 94)\n",
            "... Continuing the process\n",
            "\n",
            "After testing all possible combinations, we find that the correct combination is:\n",
            "Chickens: 23, Rabbits: 12\n",
            "\n",
            "There are 23 chickens and 12 rabbits.\n",
            "\n",
            "Confidence Level: Medium\n",
            "\n",
            "---\n",
            "\n",
            "Path 3: Working Backward from Legs\n",
            "\n",
            "Assuming all animals are chickens, they would have 70 legs (35 * 2).\n",
            "The extra legs beyond 70 must come from rabbits, which have 2 extra legs compared to chickens.\n",
            "\n",
            "Total extra legs = 94 - 70 = 24\n",
            "Number of rabbits = 24 / 2 = 12\n",
            "\n",
            "There are 12 rabbits and the remaining animals are chickens, which are 23.\n",
            "\n",
            "Confidence Level: High\n",
            "\n",
            "---\n",
            "\n",
            "Final Answer:\n",
            "After comparing the results from all three paths, it is clear that there a...\n",
            "[Response truncated for readability]\n",
            "\n",
            "üîπ ReAct Response (Temperature: 0.5):\n",
            "--------------------------------------------------\n",
            "Thought: Let's define variables for the number of chickens and rabbits in the cage. We know that chickens have 2 legs and rabbits have 4 legs. We can set up a system of equations based on the information given.\n",
            "\n",
            "Action: Let c be the number of chickens and r be the number of rabbits. We can create two equations based on the number of heads and legs: c + r = 35 (total number of heads) and 2c + 4r = 94 (total number of legs).\n",
            "\n",
            "Observation: Now, we have a system of two equations:\n",
            "1) c + r = 35\n",
            "2) 2c + 4r = 94\n",
            "\n",
            "Thought: Let's solve this system of equations to find the values of c (number of chickens) and r (number of rabbits).\n",
            "\n",
            "Action: We can start by multiplying the first equation by 2 to eliminate c:\n",
            "2(c + r) = 2(35)\n",
            "2c + 2r = 70\n",
            "\n",
            "Now, we can subtract this equation from the second equation to solve for r:\n",
            "2c + 4r - (2c + 2r) = 94 - 70\n",
            "2r = 24\n",
            "r = 12\n",
            "\n",
            "Substitute r = 12 back into the first equation to solve for c:\n",
            "c + 12 = 35\n",
            "c = 35 - 12\n",
            "c = 23\n",
            "\n",
            "Observation: There are 23 chickens and 12 rabbits in the cage.\n",
            "\n",
            "\n",
            "================================================================================\n",
            "SELF-CONSISTENCY RESULTS FOR GPT-3.5-TURBO (Temperature: 0.7)\n",
            "================================================================================\n",
            "Most Common Answer: 23 chickens and 12 rabbits\n",
            "This answer appeared 3 out of 3 times\n",
            "\n",
            "Answer Distribution:\n",
            "- 23 chickens and 12 rabbits: 3 times\n",
            "\n",
            "Sample Response:\n",
            "1) Let c be the number of chickens and r be the number of rabbits.\n",
            "\n",
            "2) Based on the information given, we can write the following equations:\n",
            "- The total number of heads: c + r = 35\n",
            "- The total number of legs: 2c + 4r = 94\n",
            "\n",
            "3) Solve the system of equations:\n",
            "From the first equation, we can express c in terms of r: c = 35 - r\n",
            "\n",
            "Substitute c in the second equation:\n",
            "2(35 - r) + 4r = 94\n",
            "70 - 2r + 4r = 94\n",
            "2r = 24\n",
            "r = 12\n",
            "\n",
            "Now, substitute r back into the first equation to find c:\n",
            "c + 12 = 35\n",
            "c = 23\n",
            "\n",
            "So, there are 23 chickens and 12 rabbits in the cage.\n",
            "\n",
            "4) Verify the answer:\n",
            "The total number of heads is 23 (chickens) + 12 (rabbits) = 35\n",
            "The total number of legs is 2(23) + 4(12) = 46 + 48 = 94\n",
            "\n",
            "Therefore, the solution is correct.\n",
            "\n",
            "\n",
            "================================================================================\n",
            "DETAILED RESULTS FOR GPT-4-TURBO\n",
            "================================================================================\n",
            "\n",
            "üîπ Chain-of-Thought Response (Temperature: 0.0):\n",
            "--------------------------------------------------\n",
            "Step 1: Define Variables\n",
            "Let \\( c \\) represent the number of chickens and \\( r \\) represent the number of rabbits.\n",
            "\n",
            "Step 2: Write Equations\n",
            "From the problem, we know:\n",
            "- Each animal has one head. Therefore, the total number of heads (chickens plus rabbits) gives us the equation:\n",
            "  \\[ c + r = 35 \\]\n",
            "- Chickens have 2 legs each and rabbits have 4 legs each. Therefore, the total number of legs gives us the equation:\n",
            "  \\[ 2c + 4r = 94 \\]\n",
            "\n",
            "Step 3: Solve the System of Equations\n",
            "We can simplify the second equation by dividing every term by 2:\n",
            "\\[ c + 2r = 47 \\]\n",
            "\n",
            "Now we have the system:\n",
            "\\[ c + r = 35 \\]\n",
            "\\[ c + 2r = 47 \\]\n",
            "\n",
            "Subtract the first equation from the second equation:\n",
            "\\[ (c + 2r) - (c + r) = 47 - 35 \\]\n",
            "\\[ r = 12 \\]\n",
            "\n",
            "Substitute \\( r = 12 \\) back into the first equation:\n",
            "\\[ c + 12 = 35 \\]\n",
            "\\[ c = 35 - 12 \\]\n",
            "\\[ c = 23 \\]\n",
            "\n",
            "Step 4: Verify the Answer\n",
            "We found \\( c = 23 \\) (chickens) and \\( r = 12 \\) (rabbits). We can check our work by plugging these values back into the original conditions:\n",
            "- Total heads: \\( 23 + 12 = 35 \\) (correct)\n",
            "- Total legs: \\( 2 \\times 23 + 4 \\times 12 = 46 + 48 = 94 \\) (correct)\n",
            "\n",
            "Thus, there are 23 chickens and 12 rabbits in the cage.\n",
            "\n",
            "üîπ Tree-of-Thought Response (Temperature: 0.7):\n",
            "--------------------------------------------------\n",
            "Let's explore each solution path:\n",
            "\n",
            "### Path 1: Algebraic Solution\n",
            "\n",
            "Let \\( c \\) be the number of chickens and \\( r \\) be the number of rabbits.\n",
            "\n",
            "1. Equation for heads: \\( c + r = 35 \\)\n",
            "2. Equation for legs: \\( 2c + 4r = 94 \\)\n",
            "\n",
            "We can solve these equations simultaneously.\n",
            "\n",
            "From equation 1:\n",
            "\\[ r = 35 - c \\]\n",
            "\n",
            "Substitute \\( r \\) in equation 2:\n",
            "\\[ 2c + 4(35 - c) = 94 \\]\n",
            "\\[ 2c + 140 - 4c = 94 \\]\n",
            "\\[ -2c = 94 - 140 \\]\n",
            "\\[ -2c = -46 \\]\n",
            "\\[ c = 23 \\]\n",
            "\n",
            "Substituting \\( c = 23 \\) back into equation 1:\n",
            "\\[ r = 35 - 23 = 12 \\]\n",
            "\n",
            "So there are 23 chickens and 12 rabbits.\n",
            "\n",
            "### Path 2: Trial and Error with Constraints\n",
            "\n",
            "We know there are 35 heads. We need to find combinations of chickens and rabbits that sum to 35 and check each for the correct number of legs.\n",
            "\n",
            "Example trials:\n",
            "- 20 chickens, 15 rabbits: \\( 2*20 + 4*15 = 40 + 60 = 100 \\) legs (wrong)\n",
            "- 23 chickens, 12 rabbits: \\( 2*23 + 4*12 = 46 + 48 = 94 \\) legs (correct)\n",
            "\n",
            "This trial correctly matches the number of legs, so 23 chickens and 12 rabbits is a possible solution.\n",
            "\n",
            "### Path 3: Working Backward from Legs\n",
            "\n",
            "Assuming all were chickens (2 legs each):\n",
            "- Total legs if all were chickens: \\( 35 \\times 2 = 70 \\) legs\n",
            "- Extra legs needed: \\( 94 - 70 = 24 \\) legs\n",
            "\n",
            "Since each rabbit has 2 more legs than a chicken:\n",
            "- Number of rabbits = \\( \\frac{24}{2} = 12 \\)\n",
            "\n",
            "So, there are 12 rabbits. Since there are 35 animals total:\n",
            "- Number of chickens = \\( 35 - 12 = 23 \\)\n",
            "\n",
            "### Comparison and Confidence in Results\n",
            "\n",
            "All three paths lead to the same answer:\n",
            "- **23 ch...\n",
            "[Response truncated for readability]\n",
            "\n",
            "üîπ ReAct Response (Temperature: 0.5):\n",
            "--------------------------------------------------\n",
            "### Cycle 1\n",
            "\n",
            "**Thought:** \n",
            "To solve this problem, I need to set up equations based on the information provided. I know that each animal has one head, so the total number of heads gives me the total number of animals. Each type of animal has a different number of legs: chickens have 2 legs and rabbits have 4 legs. I can use these facts to set up a system of equations.\n",
            "\n",
            "**Action:** \n",
            "Let \\(C\\) represent the number of chickens and \\(R\\) represent the number of rabbits. The first equation comes from the total number of heads:\n",
            "\\[ C + R = 35 \\]\n",
            "The second equation comes from the total number of legs:\n",
            "\\[ 2C + 4R = 94 \\]\n",
            "\n",
            "**Observation:** \n",
            "I have two equations:\n",
            "1. \\( C + R = 35 \\)\n",
            "2. \\( 2C + 4R = 94 \\)\n",
            "\n",
            "These equations are correctly set up based on the problem's information. I need to solve this system to find the values of \\(C\\) and \\(R\\).\n",
            "\n",
            "### Cycle 2\n",
            "\n",
            "**Thought:** \n",
            "I can simplify the second equation by dividing every term by 2, which might make it easier to solve the system using either substitution or elimination.\n",
            "\n",
            "**Action:** \n",
            "Divide the second equation by 2:\n",
            "\\[ C + 2R = 47 \\]\n",
            "\n",
            "**Observation:** \n",
            "Now I have:\n",
            "1. \\( C + R = 35 \\)\n",
            "2. \\( C + 2R = 47 \\)\n",
            "\n",
            "This simplification is correct and aligns with the problem's constraints. The system is now easier to handle.\n",
            "\n",
            "### Cycle 3\n",
            "\n",
            "**Thought:** \n",
            "I can use the elimination method to solve this system of equations. If I subtract the first equation from the second, I can eliminate \\(C\\) and solve for \\(R\\).\n",
            "\n",
            "**Action:** \n",
            "Subtract the first equat...\n",
            "[Response truncated for readability]\n",
            "\n",
            "\n",
            "================================================================================\n",
            "SELF-CONSISTENCY RESULTS FOR GPT-4-TURBO (Temperature: 0.7)\n",
            "================================================================================\n",
            "Most Common Answer: 23 chickens and 12 rabbits\n",
            "This answer appeared 3 out of 3 times\n",
            "\n",
            "Answer Distribution:\n",
            "- 23 chickens and 12 rabbits: 3 times\n",
            "\n",
            "Sample Response:\n",
            "**Step 1: Define Variables**\n",
            "Let \\( c \\) represent the number of chickens and \\( r \\) represent the number of rabbits.\n",
            "\n",
            "**Step 2: Write Equations**\n",
            "\n",
            "From the problem, we know that:\n",
            "- Each chicken and each rabbit has one head.\n",
            "- The total number of heads (chickens plus rabbits) is 35.\n",
            "- Chickens have 2 legs each, and rabbits have 4 legs each.\n",
            "- The total number of legs is 94.\n",
            "\n",
            "We can write two equations based on this information:\n",
            "1. Equation for the total number of heads:\n",
            "   \\[ c + r = 35 \\]\n",
            "2. Equation for the total number of legs:\n",
            "   \\[ 2c + 4r = 94 \\]\n",
            "\n",
            "**Step 3: Solve the System of Equations**\n",
            "\n",
            "Start with the first equation:\n",
            "\\[ c + r = 35 \\]\n",
            "Solve for \\( c \\):\n",
            "\\[ c = 35 - r \\]\n",
            "\n",
            "Substitute \\( c = 35 - r \\) into the second equation:\n",
            "\\[ 2(35 - r) + 4r = 94 \\]\n",
            "\\[ 70 - 2r + 4r = 94 \\]\n",
            "\\[ 2r = 94 - 70 \\]\n",
            "\\[ 2r = 24 \\]\n",
            "\\[ r = 12 \\]\n",
            "\n",
            "Now substitute \\( r = 12 \\) back into the equation for \\( c \\):\n",
            "\\[ c = 35 - 12 \\]\n",
            "\\[ c = 23 \\]\n",
            "\n",
            "**Step 4: Verify the Answer**\n",
            "\n",
            "We need to check that the number of legs also matches:\n",
            "- Chickens: \\( 23 \\) chickens √ó \\( 2 \\) legs/chicken = \\( 46 \\) legs\n",
            "- Rabbits: \\( 12 \\) rabbits √ó \\( 4 \\) legs/rabbit = \\( 48 \\) legs\n",
            "- Total legs = \\( 46 + 48 = 94 \\) legs\n",
            "\n",
            "Both the head count and the leg count are correct. Therefore, there are 23 chickens and 12 rabbits in the cage.\n",
            "\n",
            "\n",
            "================================================================================\n",
            "TEMPERATURE SETTINGS SUMMARY\n",
            "================================================================================\n",
            "The following temperature settings were used for each prompting strategy:\n",
            "- COT: 0.0\n",
            "- TOT: 0.7\n",
            "- REACT: 0.5\n",
            "- SELF_CONSISTENCY: 0.7\n",
            "\n",
            "Impact of Temperature Settings:\n",
            "- Lower temperature (0.0) for Chain-of-Thought: More deterministic reasoning, consistent solution paths\n",
            "- Higher temperature (0.7) for Tree-of-Thought: Encourages exploration of multiple solution paths\n",
            "- Medium temperature (0.5) for ReAct: Balance between creativity and structure in reasoning steps\n",
            "- Higher temperature (0.7) for Self-Consistency: Generates diverse reasoning attempts to find consensus\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background: linear-gradient(135deg, #001a70 0%, #0055d4 100%); color: white; padding: 25px; border-radius: 12px; text-align: center;\">\n",
        "    <h1 style=\"margin-bottom: 10px;\">üìå Conclusion</h1>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4; margin-top: 20px;\">\n",
        "    <p style=\"font-size: 16px; line-height: 1.8;\">\n",
        "        In this hands-on exploration, different advanced prompting strategies were tested to solve reasoning-based challenges.\n",
        "        Through experimenting with <strong>Chain-of-Thought (CoT)</strong>, <strong>Self-Consistency</strong>, and other methods,\n",
        "        the following key insights were observed:\n",
        "    </p>\n",
        "    <ul style=\"font-size: 16px; line-height: 1.8;\">\n",
        "        <li>Advanced prompting techniques significantly improve model performance, especially on complex, multi-step problems.</li>\n",
        "        <li>Changing the <strong>model type</strong> and <strong>temperature</strong> can drastically affect reasoning quality and creativity.</li>\n",
        "        <li>Some strategies, like <strong>Self-Consistency</strong>, help reduce random errors by exploring multiple reasoning paths.</li>\n",
        "        <li>For ambiguous or challenging problems, combining strategies (e.g., CoT + Self-Consistency) often leads to the most reliable results.</li>\n",
        "    </ul>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #f5faff; padding: 20px; border-radius: 8px; border-left: 5px solid #0055d4; margin-top: 20px;\">\n",
        "    <p style=\"font-size: 16px; font-style: italic;\">\n",
        "        üìñ <em>Remember: Prompt engineering is both an art and a science. The more you experiment, the better you understand how to guide LLMs effectively!</em>\n",
        "    </p>\n",
        "</div>\n",
        "\n",
        "<div style=\"margin-top: 40px; text-align: center;\">\n",
        "    <h3 style=\"color: #001a70;\">‚úçÔ∏è Final Reflection</h3>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4;\">\n",
        "    <p style=\"font-size: 16px;\">\n",
        "        Reflection on Prompting Strategies Experiment\n",
        "\n",
        "Through my experiment with the chickens and rabbits problem, I gained several key insights about the interplay between prompting strategies and model selection. I observed that while both GPT-3.5-Turbo and GPT-4-Turbo achieved perfect accuracy across all techniques, the reasoning patterns and explanation depth differed significantly between models when examining their detailed responses. I found particularly interesting how temperature settings affected the diversity of reasoning paths‚Äîwith lower temperatures (0.0) producing deterministic solutions for CoT, while higher temperatures for ToT (0.7) encouraged exploration of multiple solution approaches without compromising accuracy for this well-defined problem. My results suggest that for straightforward mathematical problems, the base capability of the model may be more influential than the specific prompting technique employed, though I expect these differences would become more pronounced when tackling problems with higher ambiguity or complexity.\n",
        "    </p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "sivjpWXsmlUJ"
      }
    }
  ]
}